{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPzQX2bd8WMJMqxdBI4sgsc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rishabh5752/MHD-DAIC-/blob/main/DAIC_ML_DL_Algorithm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import xgboost as xgb\n",
        "\n",
        "# Load the dataset (replace 'merged_data.csv' with your actual dataset file)\n",
        "data = pd.read_csv('merged_data.csv')\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop(['Participant_ID', 'PHQ_8Total'], axis=1).values\n",
        "y = data['PHQ_8Total'].values\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Initialize lists to store MSE and R-squared scores\n",
        "mse_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Random Forest Regression\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_predictions = rf_model.predict(X_test)\n",
        "rf_mse = mean_squared_error(y_test, rf_predictions)\n",
        "rf_r2 = r2_score(y_test, rf_predictions)\n",
        "print(f\"Random Forest MSE: {rf_mse:.4f}, R-squared: {rf_r2:.4f}\")\n",
        "mse_scores.append(rf_mse)\n",
        "r2_scores.append(rf_r2)\n",
        "\n",
        "# XGBoost Regressor\n",
        "xgb_model = xgb.XGBRegressor(random_state=42)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "xgb_predictions = xgb_model.predict(X_test)\n",
        "xgb_mse = mean_squared_error(y_test, xgb_predictions)\n",
        "xgb_r2 = r2_score(y_test, xgb_predictions)\n",
        "print(f\"XGBoost MSE: {xgb_mse:.4f}, R-squared: {xgb_r2:.4f}\")\n",
        "mse_scores.append(xgb_mse)\n",
        "r2_scores.append(xgb_r2)\n",
        "\n",
        "# Support Vector Machines (SVM)\n",
        "svm_model = SVR()\n",
        "svm_model.fit(X_train, y_train)\n",
        "svm_predictions = svm_model.predict(X_test)\n",
        "svm_mse = mean_squared_error(y_test, svm_predictions)\n",
        "svm_r2 = r2_score(y_test, svm_predictions)\n",
        "print(f\"SVM MSE: {svm_mse:.4f}, R-squared: {svm_r2:.4f}\")\n",
        "mse_scores.append(svm_mse)\n",
        "r2_scores.append(svm_r2)\n",
        "\n",
        "# K-Nearest Neighbors (KNN)\n",
        "knn_model = KNeighborsRegressor()\n",
        "knn_model.fit(X_train, y_train)\n",
        "knn_predictions = knn_model.predict(X_test)\n",
        "knn_mse = mean_squared_error(y_test, knn_predictions)\n",
        "knn_r2 = r2_score(y_test, knn_predictions)\n",
        "print(f\"KNN MSE: {knn_mse:.4f}, R-squared: {knn_r2:.4f}\")\n",
        "mse_scores.append(knn_mse)\n",
        "r2_scores.append(knn_r2)\n",
        "\n",
        "# Linear Regression\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "lr_predictions = lr_model.predict(X_test)\n",
        "lr_mse = mean_squared_error(y_test, lr_predictions)\n",
        "lr_r2 = r2_score(y_test, lr_predictions)\n",
        "print(f\"Linear Regression MSE: {lr_mse:.4f}, R-squared: {lr_r2:.4f}\")\n",
        "mse_scores.append(lr_mse)\n",
        "r2_scores.append(lr_r2)\n",
        "\n",
        "# AdaBoost Regressor\n",
        "adaboost_model = AdaBoostRegressor(random_state=42)\n",
        "adaboost_model.fit(X_train, y_train)\n",
        "adaboost_predictions = adaboost_model.predict(X_test)\n",
        "adaboost_mse = mean_squared_error(y_test, adaboost_predictions)\n",
        "adaboost_r2 = r2_score(y_test, adaboost_predictions)\n",
        "print(f\"AdaBoost MSE: {adaboost_mse:.4f}, R-squared: {adaboost_r2:.4f}\")\n",
        "mse_scores.append(adaboost_mse)\n",
        "r2_scores.append(adaboost_r2)\n",
        "\n",
        "# Compare MSE and R-squared scores\n",
        "best_model_index_mse = mse_scores.index(min(mse_scores))\n",
        "best_model_index_r2 = r2_scores.index(max(r2_scores))\n",
        "\n",
        "print(\"\\nBest model based on MSE:\", [\"Random Forest\", \"XGBoost\", \"SVM\", \"KNN\", \"Linear Regression\", \"AdaBoost\"][best_model_index_mse])\n",
        "print(\"Best model based on R-squared:\", [\"Random Forest\", \"XGBoost\", \"SVM\", \"KNN\", \"Linear Regression\", \"AdaBoost\"][best_model_index_r2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TPlHU6M__Zl",
        "outputId": "4dde8925-c4ec-4c2d-a96f-5c3d71be08ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest MSE: 51.9589, R-squared: -0.2579\n",
            "XGBoost MSE: 98.0127, R-squared: -1.3729\n",
            "SVM MSE: 42.3353, R-squared: -0.0249\n",
            "KNN MSE: 60.1100, R-squared: -0.4553\n",
            "Linear Regression MSE: 83.5283, R-squared: -1.0222\n",
            "AdaBoost MSE: 54.1057, R-squared: -0.3099\n",
            "\n",
            "Best model based on MSE: SVM\n",
            "Best model based on R-squared: SVM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Grid Search CV\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load the dataset (replace 'merged_data.csv' with your actual dataset file)\n",
        "data = pd.read_csv('merged_data.csv')\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop(['Participant_ID', 'PHQ_8Total'], axis=1).values\n",
        "y = data['PHQ_8Total'].values\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define the Random Forest Regressor model\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Define hyperparameters grid for tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [None, 5, 10, 15],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Perform GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and best estimator\n",
        "best_params = grid_search.best_params_\n",
        "best_estimator = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the best estimator on test data\n",
        "best_predictions = best_estimator.predict(X_test)\n",
        "best_mse = mean_squared_error(y_test, best_predictions)\n",
        "best_r2 = r2_score(y_test, best_predictions)\n",
        "\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "print(f\"Best MSE: {best_mse:.4f}\")\n",
        "print(f\"Best R-squared: {best_r2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzFcHbvRAuZb",
        "outputId": "c3822c09-9fc7-4c17-e55d-9d470b451af3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 150}\n",
            "Best MSE: 46.1390\n",
            "Best R-squared: -0.1170\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "C_UV85utBwVt",
        "outputId": "21d7a10b-ac54-4b4f-c17d-e59ee2655732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Participant_ID  PHQ_8Total          0          1          2      3  \\\n",
              "count       56.000000   56.000000  56.000000  56.000000  56.000000   56.0   \n",
              "mean       464.071429    4.714286   0.821429   0.821429   0.821429  255.0   \n",
              "std         16.739564    5.466308   6.147009   6.147009   6.147009    0.0   \n",
              "min        436.000000    0.000000   0.000000   0.000000   0.000000  255.0   \n",
              "25%        449.750000    1.000000   0.000000   0.000000   0.000000  255.0   \n",
              "50%        464.500000    3.000000   0.000000   0.000000   0.000000  255.0   \n",
              "75%        478.250000    7.000000   0.000000   0.000000   0.000000  255.0   \n",
              "max        492.000000   19.000000  46.000000  46.000000  46.000000  255.0   \n",
              "\n",
              "               4          5          6      7  ...       980       981  \\\n",
              "count  56.000000  56.000000  56.000000   56.0  ...  56.00000  56.00000   \n",
              "mean    1.000000   1.000000   1.000000  255.0  ...   0.50000   0.50000   \n",
              "std     4.752033   4.752033   4.752033    0.0  ...   3.03315   3.03315   \n",
              "min     0.000000   0.000000   0.000000  255.0  ...   0.00000   0.00000   \n",
              "25%     0.000000   0.000000   0.000000  255.0  ...   0.00000   0.00000   \n",
              "50%     0.000000   0.000000   0.000000  255.0  ...   0.00000   0.00000   \n",
              "75%     0.000000   0.000000   0.000000  255.0  ...   0.00000   0.00000   \n",
              "max    30.000000  30.000000  30.000000  255.0  ...  22.00000  22.00000   \n",
              "\n",
              "            982    983        984        985        986    987        988  \\\n",
              "count  56.00000   56.0  56.000000  56.000000  56.000000   56.0  56.000000   \n",
              "mean    0.50000  255.0   0.785714   0.785714   0.785714  255.0   1.178571   \n",
              "std     3.03315    0.0   5.362205   5.362205   5.362205    0.0   7.231515   \n",
              "min     0.00000  255.0   0.000000   0.000000   0.000000  255.0   0.000000   \n",
              "25%     0.00000  255.0   0.000000   0.000000   0.000000  255.0   0.000000   \n",
              "50%     0.00000  255.0   0.000000   0.000000   0.000000  255.0   0.000000   \n",
              "75%     0.00000  255.0   0.000000   0.000000   0.000000  255.0   0.000000   \n",
              "max    22.00000  255.0  40.000000  40.000000  40.000000  255.0  53.000000   \n",
              "\n",
              "             989  \n",
              "count  56.000000  \n",
              "mean    1.178571  \n",
              "std     7.231515  \n",
              "min     0.000000  \n",
              "25%     0.000000  \n",
              "50%     0.000000  \n",
              "75%     0.000000  \n",
              "max    53.000000  \n",
              "\n",
              "[8 rows x 992 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-79837b0d-1d24-4e4d-8470-41399720ced5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Participant_ID</th>\n",
              "      <th>PHQ_8Total</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>...</th>\n",
              "      <th>980</th>\n",
              "      <th>981</th>\n",
              "      <th>982</th>\n",
              "      <th>983</th>\n",
              "      <th>984</th>\n",
              "      <th>985</th>\n",
              "      <th>986</th>\n",
              "      <th>987</th>\n",
              "      <th>988</th>\n",
              "      <th>989</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>56.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>56.0</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>56.0</td>\n",
              "      <td>...</td>\n",
              "      <td>56.00000</td>\n",
              "      <td>56.00000</td>\n",
              "      <td>56.00000</td>\n",
              "      <td>56.0</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>56.0</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>56.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>464.071429</td>\n",
              "      <td>4.714286</td>\n",
              "      <td>0.821429</td>\n",
              "      <td>0.821429</td>\n",
              "      <td>0.821429</td>\n",
              "      <td>255.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>255.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.50000</td>\n",
              "      <td>0.50000</td>\n",
              "      <td>0.50000</td>\n",
              "      <td>255.0</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>255.0</td>\n",
              "      <td>1.178571</td>\n",
              "      <td>1.178571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>16.739564</td>\n",
              "      <td>5.466308</td>\n",
              "      <td>6.147009</td>\n",
              "      <td>6.147009</td>\n",
              "      <td>6.147009</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.752033</td>\n",
              "      <td>4.752033</td>\n",
              "      <td>4.752033</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.03315</td>\n",
              "      <td>3.03315</td>\n",
              "      <td>3.03315</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.362205</td>\n",
              "      <td>5.362205</td>\n",
              "      <td>5.362205</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.231515</td>\n",
              "      <td>7.231515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>436.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>255.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>255.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>255.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>255.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>449.750000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>255.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>255.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>255.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>255.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>464.500000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>255.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>255.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>255.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>255.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>478.250000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>255.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>255.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>255.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>255.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>492.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>255.0</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>255.0</td>\n",
              "      <td>...</td>\n",
              "      <td>22.00000</td>\n",
              "      <td>22.00000</td>\n",
              "      <td>22.00000</td>\n",
              "      <td>255.0</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>255.0</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>53.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 992 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79837b0d-1d24-4e4d-8470-41399720ced5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-79837b0d-1d24-4e4d-8470-41399720ced5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-79837b0d-1d24-4e4d-8470-41399720ced5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ae758f64-36b3-48bc-a4a6-e98259714b46\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ae758f64-36b3-48bc-a4a6-e98259714b46')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ae758f64-36b3-48bc-a4a6-e98259714b46 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "7Maq1hTsCck1",
        "outputId": "64d7bbf5-4854-465c-b015-61562c859886"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Participant_ID  PHQ_8Total  0  1  2    3  4  5  6    7  ...  980  981  982  \\\n",
              "0             436           0  0  0  0  255  0  0  0  255  ...    0    0    0   \n",
              "1             437           0  0  0  0  255  0  0  0  255  ...    0    0    0   \n",
              "2             438           2  0  0  0  255  0  0  0  255  ...    0    0    0   \n",
              "3             439           1  0  0  0  255  0  0  0  255  ...    0    0    0   \n",
              "4             440          19  0  0  0  255  0  0  0  255  ...    0    0    0   \n",
              "\n",
              "   983  984  985  986  987  988  989  \n",
              "0  255    0    0    0  255    0    0  \n",
              "1  255    0    0    0  255    0    0  \n",
              "2  255    4    4    4  255    0    0  \n",
              "3  255    0    0    0  255    0    0  \n",
              "4  255    0    0    0  255    0    0  \n",
              "\n",
              "[5 rows x 992 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8f738b7-bb05-406d-870b-f191998bacfe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Participant_ID</th>\n",
              "      <th>PHQ_8Total</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>...</th>\n",
              "      <th>980</th>\n",
              "      <th>981</th>\n",
              "      <th>982</th>\n",
              "      <th>983</th>\n",
              "      <th>984</th>\n",
              "      <th>985</th>\n",
              "      <th>986</th>\n",
              "      <th>987</th>\n",
              "      <th>988</th>\n",
              "      <th>989</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>436</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>255</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>255</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>255</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>255</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>437</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>255</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>255</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>255</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>255</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>438</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>255</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>255</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>255</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>255</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>439</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>255</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>255</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>255</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>255</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>440</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>255</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>255</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>255</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>255</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 992 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8f738b7-bb05-406d-870b-f191998bacfe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d8f738b7-bb05-406d-870b-f191998bacfe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d8f738b7-bb05-406d-870b-f191998bacfe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a38cfc50-38f8-420e-9db3-c82cbd965fa6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a38cfc50-38f8-420e-9db3-c82cbd965fa6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a38cfc50-38f8-420e-9db3-c82cbd965fa6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset (Replace 'merged_data.csv' with your dataset file)\n",
        "data = pd.read_csv('merged_data.csv')\n",
        "\n",
        "# Explore data\n",
        "print(data.head())  # Display the first few rows\n",
        "print(data.describe())  # Summary statistics\n",
        "\n",
        "# Visualize the distribution of 'PHQ_8Total'\n",
        "sns.histplot(data['PHQ_8Total'], kde=True)\n",
        "plt.xlabel('PHQ_8Total')\n",
        "plt.title('Distribution of PHQ_8Total')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HtpZINVLDbaT",
        "outputId": "804edbd7-d0c7-4e85-97b8-27ad3c4f8fc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Participant_ID  PHQ_8Total  0  1  2    3  4  5  6    7  ...  980  981  982  \\\n",
            "0             436           0  0  0  0  255  0  0  0  255  ...    0    0    0   \n",
            "1             437           0  0  0  0  255  0  0  0  255  ...    0    0    0   \n",
            "2             438           2  0  0  0  255  0  0  0  255  ...    0    0    0   \n",
            "3             439           1  0  0  0  255  0  0  0  255  ...    0    0    0   \n",
            "4             440          19  0  0  0  255  0  0  0  255  ...    0    0    0   \n",
            "\n",
            "   983  984  985  986  987  988  989  \n",
            "0  255    0    0    0  255    0    0  \n",
            "1  255    0    0    0  255    0    0  \n",
            "2  255    4    4    4  255    0    0  \n",
            "3  255    0    0    0  255    0    0  \n",
            "4  255    0    0    0  255    0    0  \n",
            "\n",
            "[5 rows x 992 columns]\n",
            "       Participant_ID  PHQ_8Total          0          1          2      3  \\\n",
            "count       56.000000   56.000000  56.000000  56.000000  56.000000   56.0   \n",
            "mean       464.071429    4.714286   0.821429   0.821429   0.821429  255.0   \n",
            "std         16.739564    5.466308   6.147009   6.147009   6.147009    0.0   \n",
            "min        436.000000    0.000000   0.000000   0.000000   0.000000  255.0   \n",
            "25%        449.750000    1.000000   0.000000   0.000000   0.000000  255.0   \n",
            "50%        464.500000    3.000000   0.000000   0.000000   0.000000  255.0   \n",
            "75%        478.250000    7.000000   0.000000   0.000000   0.000000  255.0   \n",
            "max        492.000000   19.000000  46.000000  46.000000  46.000000  255.0   \n",
            "\n",
            "               4          5          6      7  ...       980       981  \\\n",
            "count  56.000000  56.000000  56.000000   56.0  ...  56.00000  56.00000   \n",
            "mean    1.000000   1.000000   1.000000  255.0  ...   0.50000   0.50000   \n",
            "std     4.752033   4.752033   4.752033    0.0  ...   3.03315   3.03315   \n",
            "min     0.000000   0.000000   0.000000  255.0  ...   0.00000   0.00000   \n",
            "25%     0.000000   0.000000   0.000000  255.0  ...   0.00000   0.00000   \n",
            "50%     0.000000   0.000000   0.000000  255.0  ...   0.00000   0.00000   \n",
            "75%     0.000000   0.000000   0.000000  255.0  ...   0.00000   0.00000   \n",
            "max    30.000000  30.000000  30.000000  255.0  ...  22.00000  22.00000   \n",
            "\n",
            "            982    983        984        985        986    987        988  \\\n",
            "count  56.00000   56.0  56.000000  56.000000  56.000000   56.0  56.000000   \n",
            "mean    0.50000  255.0   0.785714   0.785714   0.785714  255.0   1.178571   \n",
            "std     3.03315    0.0   5.362205   5.362205   5.362205    0.0   7.231515   \n",
            "min     0.00000  255.0   0.000000   0.000000   0.000000  255.0   0.000000   \n",
            "25%     0.00000  255.0   0.000000   0.000000   0.000000  255.0   0.000000   \n",
            "50%     0.00000  255.0   0.000000   0.000000   0.000000  255.0   0.000000   \n",
            "75%     0.00000  255.0   0.000000   0.000000   0.000000  255.0   0.000000   \n",
            "max    22.00000  255.0  40.000000  40.000000  40.000000  255.0  53.000000   \n",
            "\n",
            "             989  \n",
            "count  56.000000  \n",
            "mean    1.178571  \n",
            "std     7.231515  \n",
            "min     0.000000  \n",
            "25%     0.000000  \n",
            "50%     0.000000  \n",
            "75%     0.000000  \n",
            "max    53.000000  \n",
            "\n",
            "[8 rows x 992 columns]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "gUQ6bar8EkzL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04034c2a-d5c4-4cec-b31f-f73d3603d5c6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re  # Import regular expression module\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load the merged_data.csv with PHQ_8Total scores\n",
        "data = pd.read_csv('/content/merged_data.csv')\n",
        "\n",
        "# Root path to the folders containing participant-wise image folders\n",
        "root_folder_path = '/content/drive/MyDrive/daic_dataset_folder'\n",
        "\n",
        "# Lists to store image paths and corresponding PHQ_8Total scores\n",
        "image_paths = []\n",
        "phq_scores = []\n",
        "\n",
        "# Traverse through participant folders\n",
        "for participant_folder in os.listdir(root_folder_path):\n",
        "    participant_folder_path = os.path.join(root_folder_path, participant_folder)\n",
        "    if os.path.isdir(participant_folder_path):\n",
        "        # Extract participant ID from folder name using regular expression\n",
        "        match = re.search(r'\\d+', participant_folder)\n",
        "        if match:\n",
        "            participant_id = match.group()\n",
        "            for filename in os.listdir(participant_folder_path):\n",
        "                if filename.endswith('.png'):  # Assuming images are in png format\n",
        "                    image_paths.append(os.path.join(participant_folder_path, filename))\n",
        "                    # Extract PHQ_8Total score from data based on Participant_ID or any relevant mapping\n",
        "                    phq_score = data[data['Participant_ID'] == int(participant_id)]['PHQ_8Total'].values\n",
        "                    if len(phq_score) > 0:\n",
        "                        phq_scores.append(phq_score[0])\n",
        "\n",
        "# Load images and convert to arrays\n",
        "images = []\n",
        "for img_path in image_paths:\n",
        "    img = load_img(img_path, target_size=(4, 4))  # Set image height and width\n",
        "    img_array = img_to_array(img)\n",
        "    images.append(img_array)\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "images = np.array(images)\n",
        "phq_scores = np.array(phq_scores)\n",
        "\n",
        "# Check if images and phq_scores are not empty\n",
        "print(f\"Number of loaded images: {len(images)}\")\n",
        "print(f\"Number of PHQ_8Total scores: {len(phq_scores)}\")\n",
        "\n",
        "# If there are images and scores, continue\n",
        "if len(images) > 0 and len(phq_scores) > 0:\n",
        "    # Split the dataset into training and validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(images, phq_scores, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Build the CNN model\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(4, 4, 3)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    # Add more layers as needed\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(1))  # Output layer for regression\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=Adam(), loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train, epochs=1000, batch_size=10, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSGcfPO6HsRW",
        "outputId": "f37beb19-2703-46e4-84e3-abc8310de369"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of loaded images: 56\n",
            "Number of PHQ_8Total scores: 56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# If there are images and scores, continue\n",
        "if len(images) > 0 and len(phq_scores) > 0:\n",
        "    # Split the dataset into training and validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(images, phq_scores, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Build the CNN model\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(4, 4, 3)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    # Add more layers as needed\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(1))  # Output layer for regression\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=Adam(), loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train, epochs=1000, batch_size=10, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpMY3h2oH-sh",
        "outputId": "4dfe3c64-f732-4f1a-81d2-e1a840624db9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "5/5 [==============================] - 1s 45ms/step - loss: 133.9279 - mae: 9.2685 - val_loss: 147.4365 - val_mae: 9.9248\n",
            "Epoch 2/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 102.1510 - mae: 7.8333 - val_loss: 96.7039 - val_mae: 8.0613\n",
            "Epoch 3/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 49.2302 - mae: 5.2523 - val_loss: 81.0736 - val_mae: 6.9558\n",
            "Epoch 4/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 42.7307 - mae: 4.9700 - val_loss: 67.6461 - val_mae: 6.3254\n",
            "Epoch 5/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 29.6789 - mae: 4.0075 - val_loss: 67.2196 - val_mae: 6.5306\n",
            "Epoch 6/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 28.9550 - mae: 4.0065 - val_loss: 66.0861 - val_mae: 6.4279\n",
            "Epoch 7/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23.5769 - mae: 3.5395 - val_loss: 60.1805 - val_mae: 5.8559\n",
            "Epoch 8/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 25.2507 - mae: 3.5458 - val_loss: 61.3356 - val_mae: 6.1431\n",
            "Epoch 9/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 21.3119 - mae: 3.3881 - val_loss: 70.6898 - val_mae: 6.7992\n",
            "Epoch 10/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 19.9999 - mae: 3.2642 - val_loss: 66.5498 - val_mae: 6.5269\n",
            "Epoch 11/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 17.4401 - mae: 2.8964 - val_loss: 65.0310 - val_mae: 6.4901\n",
            "Epoch 12/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 16.8795 - mae: 2.8059 - val_loss: 69.5861 - val_mae: 6.7825\n",
            "Epoch 13/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 16.0184 - mae: 2.7275 - val_loss: 70.8604 - val_mae: 6.8778\n",
            "Epoch 14/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 15.4916 - mae: 2.6672 - val_loss: 67.8077 - val_mae: 6.6976\n",
            "Epoch 15/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 15.1122 - mae: 2.6090 - val_loss: 70.7359 - val_mae: 6.9212\n",
            "Epoch 16/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 14.5029 - mae: 2.5487 - val_loss: 67.4812 - val_mae: 6.7276\n",
            "Epoch 17/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 13.9919 - mae: 2.4685 - val_loss: 70.1682 - val_mae: 6.9336\n",
            "Epoch 18/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 13.4384 - mae: 2.3454 - val_loss: 69.6298 - val_mae: 6.9270\n",
            "Epoch 19/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 13.0485 - mae: 2.2387 - val_loss: 70.9636 - val_mae: 7.0353\n",
            "Epoch 20/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 12.8684 - mae: 2.2722 - val_loss: 74.2764 - val_mae: 7.2547\n",
            "Epoch 21/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 12.1661 - mae: 2.0912 - val_loss: 70.1043 - val_mae: 7.0186\n",
            "Epoch 22/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 12.1286 - mae: 2.0544 - val_loss: 72.8136 - val_mae: 7.2123\n",
            "Epoch 23/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11.8159 - mae: 2.0150 - val_loss: 74.1413 - val_mae: 7.3241\n",
            "Epoch 24/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.5540 - mae: 1.9672 - val_loss: 73.3600 - val_mae: 7.3051\n",
            "Epoch 25/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11.1051 - mae: 1.8462 - val_loss: 78.7137 - val_mae: 7.6051\n",
            "Epoch 26/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 10.9160 - mae: 1.8537 - val_loss: 75.3980 - val_mae: 7.4500\n",
            "Epoch 27/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 10.9039 - mae: 1.8196 - val_loss: 74.2391 - val_mae: 7.4050\n",
            "Epoch 28/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 10.4169 - mae: 1.7215 - val_loss: 78.8328 - val_mae: 7.6707\n",
            "Epoch 29/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 10.1747 - mae: 1.6688 - val_loss: 78.4508 - val_mae: 7.6795\n",
            "Epoch 30/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 9.9992 - mae: 1.6073 - val_loss: 80.2028 - val_mae: 7.7931\n",
            "Epoch 31/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 9.7477 - mae: 1.5605 - val_loss: 80.2463 - val_mae: 7.8169\n",
            "Epoch 32/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 9.6169 - mae: 1.5091 - val_loss: 81.1775 - val_mae: 7.8746\n",
            "Epoch 33/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 9.6726 - mae: 1.5797 - val_loss: 81.0263 - val_mae: 7.8794\n",
            "Epoch 34/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 9.3904 - mae: 1.5329 - val_loss: 78.8911 - val_mae: 7.7790\n",
            "Epoch 35/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 9.2103 - mae: 1.4457 - val_loss: 84.0555 - val_mae: 8.0556\n",
            "Epoch 36/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 9.1715 - mae: 1.4862 - val_loss: 81.3984 - val_mae: 7.9393\n",
            "Epoch 37/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 8.9985 - mae: 1.3598 - val_loss: 82.3700 - val_mae: 8.0103\n",
            "Epoch 38/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 8.9046 - mae: 1.3697 - val_loss: 83.5346 - val_mae: 8.0906\n",
            "Epoch 39/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 8.7193 - mae: 1.2615 - val_loss: 82.3774 - val_mae: 8.0576\n",
            "Epoch 40/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 8.7111 - mae: 1.2899 - val_loss: 86.3759 - val_mae: 8.2701\n",
            "Epoch 41/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 8.6094 - mae: 1.3363 - val_loss: 85.9195 - val_mae: 8.2565\n",
            "Epoch 42/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 8.4804 - mae: 1.2408 - val_loss: 84.9653 - val_mae: 8.2226\n",
            "Epoch 43/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 8.4255 - mae: 1.2303 - val_loss: 87.3355 - val_mae: 8.3552\n",
            "Epoch 44/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 8.3810 - mae: 1.3025 - val_loss: 87.1174 - val_mae: 8.3596\n",
            "Epoch 45/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 8.3717 - mae: 1.2741 - val_loss: 88.6506 - val_mae: 8.4425\n",
            "Epoch 46/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 8.5083 - mae: 1.4363 - val_loss: 87.6213 - val_mae: 8.4074\n",
            "Epoch 47/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 8.3777 - mae: 1.3474 - val_loss: 89.0805 - val_mae: 8.4872\n",
            "Epoch 48/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 7.9404 - mae: 1.2091 - val_loss: 93.4668 - val_mae: 8.6941\n",
            "Epoch 49/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 7.9483 - mae: 1.2889 - val_loss: 88.7667 - val_mae: 8.5161\n",
            "Epoch 50/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 7.9234 - mae: 1.2063 - val_loss: 93.0899 - val_mae: 8.7267\n",
            "Epoch 51/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 7.7220 - mae: 1.1623 - val_loss: 89.9802 - val_mae: 8.5941\n",
            "Epoch 52/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 7.7908 - mae: 1.1946 - val_loss: 93.3355 - val_mae: 8.7386\n",
            "Epoch 53/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 7.8150 - mae: 1.2787 - val_loss: 89.9971 - val_mae: 8.5935\n",
            "Epoch 54/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 7.6632 - mae: 1.2163 - val_loss: 91.5252 - val_mae: 8.6710\n",
            "Epoch 55/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 7.6235 - mae: 1.2356 - val_loss: 94.8059 - val_mae: 8.8515\n",
            "Epoch 56/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 7.4490 - mae: 1.1081 - val_loss: 92.7558 - val_mae: 8.7860\n",
            "Epoch 57/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 7.4507 - mae: 1.1291 - val_loss: 97.2492 - val_mae: 9.0097\n",
            "Epoch 58/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 7.4198 - mae: 1.1380 - val_loss: 97.5436 - val_mae: 9.0408\n",
            "Epoch 59/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 7.2201 - mae: 1.0822 - val_loss: 97.0934 - val_mae: 9.0225\n",
            "Epoch 60/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 7.2025 - mae: 1.0541 - val_loss: 96.5043 - val_mae: 8.9986\n",
            "Epoch 61/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 7.0959 - mae: 1.0443 - val_loss: 97.8195 - val_mae: 9.0781\n",
            "Epoch 62/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 7.0231 - mae: 0.9971 - val_loss: 99.2772 - val_mae: 9.1543\n",
            "Epoch 63/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 6.9554 - mae: 1.0106 - val_loss: 99.1937 - val_mae: 9.1548\n",
            "Epoch 64/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 6.8889 - mae: 0.9438 - val_loss: 99.0268 - val_mae: 9.1602\n",
            "Epoch 65/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 6.8257 - mae: 0.9461 - val_loss: 101.0158 - val_mae: 9.2617\n",
            "Epoch 66/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 6.7914 - mae: 0.9515 - val_loss: 103.2726 - val_mae: 9.3667\n",
            "Epoch 67/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 6.8127 - mae: 1.0503 - val_loss: 100.7328 - val_mae: 9.2740\n",
            "Epoch 68/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 6.7673 - mae: 1.0098 - val_loss: 105.4354 - val_mae: 9.4661\n",
            "Epoch 69/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 6.6558 - mae: 0.9640 - val_loss: 103.2928 - val_mae: 9.3996\n",
            "Epoch 70/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 6.5727 - mae: 0.8941 - val_loss: 106.7181 - val_mae: 9.5447\n",
            "Epoch 71/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 6.4851 - mae: 0.8879 - val_loss: 104.0878 - val_mae: 9.4389\n",
            "Epoch 72/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 6.4538 - mae: 0.8561 - val_loss: 106.2592 - val_mae: 9.5383\n",
            "Epoch 73/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 6.4206 - mae: 0.8957 - val_loss: 104.9472 - val_mae: 9.4945\n",
            "Epoch 74/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 6.3492 - mae: 0.8709 - val_loss: 105.0009 - val_mae: 9.4961\n",
            "Epoch 75/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 6.3212 - mae: 0.8482 - val_loss: 106.5416 - val_mae: 9.5624\n",
            "Epoch 76/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 6.2789 - mae: 0.8881 - val_loss: 103.9526 - val_mae: 9.4515\n",
            "Epoch 77/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 6.3159 - mae: 0.9026 - val_loss: 109.4106 - val_mae: 9.6609\n",
            "Epoch 78/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 6.2869 - mae: 0.9575 - val_loss: 102.5023 - val_mae: 9.4043\n",
            "Epoch 79/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 6.3612 - mae: 1.0298 - val_loss: 113.6777 - val_mae: 9.8391\n",
            "Epoch 80/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 6.3435 - mae: 1.0547 - val_loss: 102.5945 - val_mae: 9.4126\n",
            "Epoch 81/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 6.4805 - mae: 1.1277 - val_loss: 109.4777 - val_mae: 9.6512\n",
            "Epoch 82/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 6.3039 - mae: 1.0134 - val_loss: 110.5349 - val_mae: 9.7058\n",
            "Epoch 83/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 6.2626 - mae: 1.0396 - val_loss: 106.8670 - val_mae: 9.5882\n",
            "Epoch 84/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 6.0956 - mae: 0.9996 - val_loss: 114.6373 - val_mae: 9.8566\n",
            "Epoch 85/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 6.2681 - mae: 1.0974 - val_loss: 113.7132 - val_mae: 9.8571\n",
            "Epoch 86/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 5.8946 - mae: 0.9277 - val_loss: 112.2245 - val_mae: 9.8009\n",
            "Epoch 87/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 5.8680 - mae: 0.8920 - val_loss: 108.6880 - val_mae: 9.6187\n",
            "Epoch 88/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 5.7392 - mae: 0.7878 - val_loss: 109.3988 - val_mae: 9.6015\n",
            "Epoch 89/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 5.6623 - mae: 0.8498 - val_loss: 111.3195 - val_mae: 9.7580\n",
            "Epoch 90/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 5.5574 - mae: 0.7757 - val_loss: 115.9878 - val_mae: 9.9704\n",
            "Epoch 91/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 5.5850 - mae: 0.8652 - val_loss: 109.6429 - val_mae: 9.7453\n",
            "Epoch 92/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 5.6794 - mae: 1.0217 - val_loss: 115.6777 - val_mae: 9.9695\n",
            "Epoch 93/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 5.6943 - mae: 0.9600 - val_loss: 109.3738 - val_mae: 9.7493\n",
            "Epoch 94/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 5.5623 - mae: 0.9428 - val_loss: 109.0509 - val_mae: 9.7396\n",
            "Epoch 95/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 5.3284 - mae: 0.8165 - val_loss: 111.0169 - val_mae: 9.8157\n",
            "Epoch 96/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 5.1941 - mae: 0.8067 - val_loss: 108.6619 - val_mae: 9.7152\n",
            "Epoch 97/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 5.1980 - mae: 0.8636 - val_loss: 111.7149 - val_mae: 9.8620\n",
            "Epoch 98/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 5.1704 - mae: 0.9328 - val_loss: 116.9027 - val_mae: 10.0511\n",
            "Epoch 99/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 4.9995 - mae: 0.8243 - val_loss: 109.8619 - val_mae: 9.7741\n",
            "Epoch 100/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 4.9916 - mae: 0.8662 - val_loss: 109.6610 - val_mae: 9.7715\n",
            "Epoch 101/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 4.9664 - mae: 0.8721 - val_loss: 120.8063 - val_mae: 10.1782\n",
            "Epoch 102/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 5.1972 - mae: 1.1341 - val_loss: 103.7130 - val_mae: 9.5144\n",
            "Epoch 103/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.6651 - mae: 1.3621 - val_loss: 130.4053 - val_mae: 10.4966\n",
            "Epoch 104/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.5323 - mae: 1.3186 - val_loss: 115.5909 - val_mae: 10.0108\n",
            "Epoch 105/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 5.1190 - mae: 1.0632 - val_loss: 110.3653 - val_mae: 9.8165\n",
            "Epoch 106/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.9668 - mae: 1.0468 - val_loss: 113.5341 - val_mae: 9.9174\n",
            "Epoch 107/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 4.8057 - mae: 0.9878 - val_loss: 119.8055 - val_mae: 10.1865\n",
            "Epoch 108/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 4.6035 - mae: 0.9437 - val_loss: 122.1726 - val_mae: 10.2366\n",
            "Epoch 109/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 4.4925 - mae: 0.8626 - val_loss: 127.4479 - val_mae: 10.3582\n",
            "Epoch 110/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 4.5679 - mae: 0.9509 - val_loss: 116.1234 - val_mae: 10.0387\n",
            "Epoch 111/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 4.3347 - mae: 0.8479 - val_loss: 119.1790 - val_mae: 10.1691\n",
            "Epoch 112/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 4.2999 - mae: 0.8689 - val_loss: 131.3944 - val_mae: 10.5215\n",
            "Epoch 113/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.1458 - mae: 0.8671 - val_loss: 119.3359 - val_mae: 10.0977\n",
            "Epoch 114/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 4.1367 - mae: 0.8921 - val_loss: 124.9413 - val_mae: 10.3337\n",
            "Epoch 115/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 3.9571 - mae: 0.8002 - val_loss: 133.1617 - val_mae: 10.6036\n",
            "Epoch 116/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 4.2782 - mae: 1.0705 - val_loss: 111.9475 - val_mae: 9.8127\n",
            "Epoch 117/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 4.4517 - mae: 1.0902 - val_loss: 126.3941 - val_mae: 10.2643\n",
            "Epoch 118/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 4.2558 - mae: 1.0291 - val_loss: 115.9512 - val_mae: 9.8700\n",
            "Epoch 119/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 4.1978 - mae: 1.0874 - val_loss: 119.5805 - val_mae: 10.0160\n",
            "Epoch 120/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 3.5942 - mae: 0.7799 - val_loss: 117.0316 - val_mae: 9.9730\n",
            "Epoch 121/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 3.5198 - mae: 0.6980 - val_loss: 118.0945 - val_mae: 10.0132\n",
            "Epoch 122/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 3.4265 - mae: 0.6581 - val_loss: 125.4602 - val_mae: 10.2341\n",
            "Epoch 123/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 3.2569 - mae: 0.5950 - val_loss: 126.5591 - val_mae: 10.2346\n",
            "Epoch 124/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 3.2426 - mae: 0.6174 - val_loss: 125.0032 - val_mae: 10.1871\n",
            "Epoch 125/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 3.1473 - mae: 0.5742 - val_loss: 122.5910 - val_mae: 10.1121\n",
            "Epoch 126/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 3.0656 - mae: 0.5681 - val_loss: 131.5699 - val_mae: 10.4589\n",
            "Epoch 127/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 3.0023 - mae: 0.6039 - val_loss: 131.3475 - val_mae: 10.4550\n",
            "Epoch 128/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.9028 - mae: 0.5272 - val_loss: 127.4712 - val_mae: 10.2983\n",
            "Epoch 129/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.9431 - mae: 0.6035 - val_loss: 135.5157 - val_mae: 10.5497\n",
            "Epoch 130/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.8647 - mae: 0.6567 - val_loss: 129.7397 - val_mae: 10.3985\n",
            "Epoch 131/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.7954 - mae: 0.6133 - val_loss: 137.5660 - val_mae: 10.6469\n",
            "Epoch 132/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.7816 - mae: 0.6546 - val_loss: 137.6643 - val_mae: 10.6034\n",
            "Epoch 133/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.7766 - mae: 0.7053 - val_loss: 126.4683 - val_mae: 10.2551\n",
            "Epoch 134/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.8877 - mae: 0.7585 - val_loss: 135.5608 - val_mae: 10.5632\n",
            "Epoch 135/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.6009 - mae: 0.6232 - val_loss: 136.1933 - val_mae: 10.5775\n",
            "Epoch 136/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.5396 - mae: 0.6145 - val_loss: 133.3199 - val_mae: 10.4701\n",
            "Epoch 137/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 2.6215 - mae: 0.6868 - val_loss: 141.8783 - val_mae: 10.7809\n",
            "Epoch 138/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.5420 - mae: 0.6667 - val_loss: 134.2489 - val_mae: 10.5498\n",
            "Epoch 139/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.4849 - mae: 0.6592 - val_loss: 133.0045 - val_mae: 10.4865\n",
            "Epoch 140/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.3655 - mae: 0.5881 - val_loss: 144.2996 - val_mae: 10.8221\n",
            "Epoch 141/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.3486 - mae: 0.6309 - val_loss: 141.6721 - val_mae: 10.7363\n",
            "Epoch 142/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.1861 - mae: 0.5567 - val_loss: 137.7824 - val_mae: 10.5998\n",
            "Epoch 143/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.1986 - mae: 0.6192 - val_loss: 153.6252 - val_mae: 11.0926\n",
            "Epoch 144/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.0716 - mae: 0.5403 - val_loss: 143.6816 - val_mae: 10.8042\n",
            "Epoch 145/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 2.0423 - mae: 0.5148 - val_loss: 137.4638 - val_mae: 10.6178\n",
            "Epoch 146/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.9515 - mae: 0.4832 - val_loss: 137.2279 - val_mae: 10.6357\n",
            "Epoch 147/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.8657 - mae: 0.4409 - val_loss: 144.4434 - val_mae: 10.8678\n",
            "Epoch 148/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 1.8215 - mae: 0.4516 - val_loss: 148.2743 - val_mae: 10.9517\n",
            "Epoch 149/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 1.7332 - mae: 0.3856 - val_loss: 146.0781 - val_mae: 10.8433\n",
            "Epoch 150/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6968 - mae: 0.3565 - val_loss: 148.6690 - val_mae: 10.9054\n",
            "Epoch 151/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.6446 - mae: 0.3384 - val_loss: 147.6601 - val_mae: 10.8833\n",
            "Epoch 152/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.6045 - mae: 0.3417 - val_loss: 149.3745 - val_mae: 10.9532\n",
            "Epoch 153/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5538 - mae: 0.3308 - val_loss: 147.7192 - val_mae: 10.9141\n",
            "Epoch 154/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.5242 - mae: 0.3465 - val_loss: 150.5252 - val_mae: 10.9794\n",
            "Epoch 155/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4640 - mae: 0.3236 - val_loss: 152.5491 - val_mae: 11.0041\n",
            "Epoch 156/1000\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 1.4293 - mae: 0.3275 - val_loss: 158.3645 - val_mae: 11.1562\n",
            "Epoch 157/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 1.3981 - mae: 0.3278 - val_loss: 158.4014 - val_mae: 11.1792\n",
            "Epoch 158/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.3544 - mae: 0.3255 - val_loss: 154.1286 - val_mae: 11.0781\n",
            "Epoch 159/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.3552 - mae: 0.3448 - val_loss: 158.9419 - val_mae: 11.1988\n",
            "Epoch 160/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 1.2551 - mae: 0.2961 - val_loss: 162.1374 - val_mae: 11.2555\n",
            "Epoch 161/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2311 - mae: 0.3475 - val_loss: 158.2241 - val_mae: 11.1194\n",
            "Epoch 162/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2023 - mae: 0.3524 - val_loss: 158.5791 - val_mae: 11.1332\n",
            "Epoch 163/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1896 - mae: 0.3812 - val_loss: 163.6422 - val_mae: 11.2911\n",
            "Epoch 164/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.1933 - mae: 0.4261 - val_loss: 162.9598 - val_mae: 11.2725\n",
            "Epoch 165/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.0893 - mae: 0.3591 - val_loss: 163.9681 - val_mae: 11.3072\n",
            "Epoch 166/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.0333 - mae: 0.3381 - val_loss: 166.7418 - val_mae: 11.3795\n",
            "Epoch 167/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.0129 - mae: 0.3465 - val_loss: 173.2808 - val_mae: 11.5124\n",
            "Epoch 168/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.9941 - mae: 0.3890 - val_loss: 167.8726 - val_mae: 11.3568\n",
            "Epoch 169/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.9509 - mae: 0.3479 - val_loss: 171.0700 - val_mae: 11.4463\n",
            "Epoch 170/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.9146 - mae: 0.3162 - val_loss: 172.2421 - val_mae: 11.4928\n",
            "Epoch 171/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8942 - mae: 0.3426 - val_loss: 172.8964 - val_mae: 11.4945\n",
            "Epoch 172/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8802 - mae: 0.3620 - val_loss: 180.3256 - val_mae: 11.6478\n",
            "Epoch 173/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.9090 - mae: 0.4167 - val_loss: 180.9624 - val_mae: 11.6273\n",
            "Epoch 174/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.8713 - mae: 0.4072 - val_loss: 176.1780 - val_mae: 11.4970\n",
            "Epoch 175/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8185 - mae: 0.3405 - val_loss: 167.3893 - val_mae: 11.2391\n",
            "Epoch 176/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8355 - mae: 0.3617 - val_loss: 185.3207 - val_mae: 11.7181\n",
            "Epoch 177/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.9990 - mae: 0.5368 - val_loss: 177.9545 - val_mae: 11.5452\n",
            "Epoch 178/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8844 - mae: 0.4833 - val_loss: 167.2745 - val_mae: 11.2377\n",
            "Epoch 179/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.9531 - mae: 0.5112 - val_loss: 184.9781 - val_mae: 11.7294\n",
            "Epoch 180/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8081 - mae: 0.4558 - val_loss: 178.3074 - val_mae: 11.5890\n",
            "Epoch 181/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.8657 - mae: 0.5031 - val_loss: 169.5762 - val_mae: 11.3246\n",
            "Epoch 182/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7639 - mae: 0.4141 - val_loss: 183.1237 - val_mae: 11.6285\n",
            "Epoch 183/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7671 - mae: 0.4137 - val_loss: 165.9407 - val_mae: 11.1738\n",
            "Epoch 184/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.8781 - mae: 0.4912 - val_loss: 153.0623 - val_mae: 10.8089\n",
            "Epoch 185/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.7987 - mae: 0.4680 - val_loss: 153.4295 - val_mae: 10.7833\n",
            "Epoch 186/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.8429 - mae: 0.5306 - val_loss: 169.3707 - val_mae: 11.1878\n",
            "Epoch 187/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.8694 - mae: 0.5349 - val_loss: 172.7771 - val_mae: 11.2714\n",
            "Epoch 188/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.0238 - mae: 0.6528 - val_loss: 162.3248 - val_mae: 11.0298\n",
            "Epoch 189/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.2099 - mae: 0.7540 - val_loss: 149.9387 - val_mae: 10.6769\n",
            "Epoch 190/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.7689 - mae: 0.9978 - val_loss: 179.3868 - val_mae: 11.5169\n",
            "Epoch 191/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.7994 - mae: 0.9617 - val_loss: 176.7642 - val_mae: 11.3962\n",
            "Epoch 192/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.1034 - mae: 0.9693 - val_loss: 187.0490 - val_mae: 11.5375\n",
            "Epoch 193/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 3.4415 - mae: 1.5408 - val_loss: 154.3860 - val_mae: 10.8405\n",
            "Epoch 194/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 6.9035 - mae: 2.0475 - val_loss: 181.0322 - val_mae: 11.4355\n",
            "Epoch 195/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.3681 - mae: 0.8019 - val_loss: 138.3008 - val_mae: 10.0325\n",
            "Epoch 196/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 3.3983 - mae: 1.3252 - val_loss: 145.6849 - val_mae: 10.3779\n",
            "Epoch 197/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 2.3692 - mae: 1.2106 - val_loss: 183.8724 - val_mae: 11.4602\n",
            "Epoch 198/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 3.0453 - mae: 1.3310 - val_loss: 146.8363 - val_mae: 10.2934\n",
            "Epoch 199/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.7979 - mae: 1.0193 - val_loss: 159.4981 - val_mae: 10.4681\n",
            "Epoch 200/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2973 - mae: 0.8143 - val_loss: 148.1766 - val_mae: 10.1507\n",
            "Epoch 201/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2125 - mae: 0.7259 - val_loss: 161.4229 - val_mae: 10.4200\n",
            "Epoch 202/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3559 - mae: 0.8358 - val_loss: 157.7974 - val_mae: 10.4047\n",
            "Epoch 203/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.5045 - mae: 0.8408 - val_loss: 174.9442 - val_mae: 10.9788\n",
            "Epoch 204/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.8227 - mae: 0.6379 - val_loss: 165.8903 - val_mae: 10.8060\n",
            "Epoch 205/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6366 - mae: 0.4762 - val_loss: 145.4766 - val_mae: 10.3153\n",
            "Epoch 206/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6261 - mae: 0.4557 - val_loss: 160.4045 - val_mae: 10.7031\n",
            "Epoch 207/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5071 - mae: 0.3875 - val_loss: 158.8564 - val_mae: 10.6505\n",
            "Epoch 208/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.4491 - mae: 0.3218 - val_loss: 159.3730 - val_mae: 10.6453\n",
            "Epoch 209/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4357 - mae: 0.3008 - val_loss: 160.0119 - val_mae: 10.6741\n",
            "Epoch 210/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4352 - mae: 0.3171 - val_loss: 167.6047 - val_mae: 10.8897\n",
            "Epoch 211/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4046 - mae: 0.2797 - val_loss: 172.6998 - val_mae: 11.0051\n",
            "Epoch 212/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4299 - mae: 0.3612 - val_loss: 162.5646 - val_mae: 10.7419\n",
            "Epoch 213/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3988 - mae: 0.2931 - val_loss: 170.2580 - val_mae: 10.9432\n",
            "Epoch 214/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3628 - mae: 0.2368 - val_loss: 172.6932 - val_mae: 11.0049\n",
            "Epoch 215/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3558 - mae: 0.2404 - val_loss: 172.7833 - val_mae: 11.0129\n",
            "Epoch 216/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3396 - mae: 0.2173 - val_loss: 175.0495 - val_mae: 11.0730\n",
            "Epoch 217/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3225 - mae: 0.1928 - val_loss: 180.4204 - val_mae: 11.2064\n",
            "Epoch 218/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3354 - mae: 0.2442 - val_loss: 176.3867 - val_mae: 11.1176\n",
            "Epoch 219/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3250 - mae: 0.2332 - val_loss: 174.5816 - val_mae: 11.0747\n",
            "Epoch 220/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3218 - mae: 0.2256 - val_loss: 179.8426 - val_mae: 11.2065\n",
            "Epoch 221/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3086 - mae: 0.2248 - val_loss: 179.7596 - val_mae: 11.2169\n",
            "Epoch 222/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2948 - mae: 0.1924 - val_loss: 178.2814 - val_mae: 11.1886\n",
            "Epoch 223/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2880 - mae: 0.1776 - val_loss: 180.6467 - val_mae: 11.2444\n",
            "Epoch 224/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2831 - mae: 0.1778 - val_loss: 183.1298 - val_mae: 11.3045\n",
            "Epoch 225/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2769 - mae: 0.1784 - val_loss: 182.3455 - val_mae: 11.2900\n",
            "Epoch 226/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2734 - mae: 0.1860 - val_loss: 181.3765 - val_mae: 11.2678\n",
            "Epoch 227/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2718 - mae: 0.1929 - val_loss: 179.5361 - val_mae: 11.2123\n",
            "Epoch 228/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2645 - mae: 0.1718 - val_loss: 177.8181 - val_mae: 11.1622\n",
            "Epoch 229/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2715 - mae: 0.2072 - val_loss: 178.9600 - val_mae: 11.1880\n",
            "Epoch 230/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2556 - mae: 0.1683 - val_loss: 180.2524 - val_mae: 11.2281\n",
            "Epoch 231/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2534 - mae: 0.1726 - val_loss: 183.3868 - val_mae: 11.3004\n",
            "Epoch 232/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2421 - mae: 0.1637 - val_loss: 181.9885 - val_mae: 11.2592\n",
            "Epoch 233/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2474 - mae: 0.1925 - val_loss: 182.3201 - val_mae: 11.2613\n",
            "Epoch 234/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2429 - mae: 0.1742 - val_loss: 184.1432 - val_mae: 11.3095\n",
            "Epoch 235/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2385 - mae: 0.1839 - val_loss: 184.9136 - val_mae: 11.3392\n",
            "Epoch 236/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2321 - mae: 0.1548 - val_loss: 182.8811 - val_mae: 11.3000\n",
            "Epoch 237/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.2258 - mae: 0.1486 - val_loss: 186.3662 - val_mae: 11.3920\n",
            "Epoch 238/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2233 - mae: 0.1635 - val_loss: 185.4855 - val_mae: 11.3738\n",
            "Epoch 239/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.2199 - mae: 0.1675 - val_loss: 186.0113 - val_mae: 11.3698\n",
            "Epoch 240/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2149 - mae: 0.1459 - val_loss: 186.2938 - val_mae: 11.3608\n",
            "Epoch 241/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2112 - mae: 0.1489 - val_loss: 186.2744 - val_mae: 11.3565\n",
            "Epoch 242/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2073 - mae: 0.1428 - val_loss: 188.7160 - val_mae: 11.4216\n",
            "Epoch 243/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2060 - mae: 0.1473 - val_loss: 186.8600 - val_mae: 11.3875\n",
            "Epoch 244/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2032 - mae: 0.1485 - val_loss: 186.4573 - val_mae: 11.3755\n",
            "Epoch 245/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2022 - mae: 0.1557 - val_loss: 188.8728 - val_mae: 11.4317\n",
            "Epoch 246/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1943 - mae: 0.1411 - val_loss: 189.2326 - val_mae: 11.4361\n",
            "Epoch 247/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1912 - mae: 0.1395 - val_loss: 189.0391 - val_mae: 11.4253\n",
            "Epoch 248/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1869 - mae: 0.1288 - val_loss: 190.1139 - val_mae: 11.4473\n",
            "Epoch 249/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1838 - mae: 0.1228 - val_loss: 191.2385 - val_mae: 11.4707\n",
            "Epoch 250/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1823 - mae: 0.1204 - val_loss: 193.8192 - val_mae: 11.5328\n",
            "Epoch 251/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1788 - mae: 0.1437 - val_loss: 194.5255 - val_mae: 11.5594\n",
            "Epoch 252/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1770 - mae: 0.1413 - val_loss: 193.6360 - val_mae: 11.5371\n",
            "Epoch 253/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1797 - mae: 0.1693 - val_loss: 192.5760 - val_mae: 11.4935\n",
            "Epoch 254/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1777 - mae: 0.1539 - val_loss: 194.5967 - val_mae: 11.5411\n",
            "Epoch 255/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1723 - mae: 0.1637 - val_loss: 195.7087 - val_mae: 11.5748\n",
            "Epoch 256/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1726 - mae: 0.1681 - val_loss: 195.5849 - val_mae: 11.5789\n",
            "Epoch 257/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1751 - mae: 0.1900 - val_loss: 195.9268 - val_mae: 11.5772\n",
            "Epoch 258/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1704 - mae: 0.1679 - val_loss: 198.8990 - val_mae: 11.6381\n",
            "Epoch 259/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1908 - mae: 0.2497 - val_loss: 208.1108 - val_mae: 11.8442\n",
            "Epoch 260/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2845 - mae: 0.2879 - val_loss: 180.4958 - val_mae: 11.1929\n",
            "Epoch 261/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3720 - mae: 0.3775 - val_loss: 165.4483 - val_mae: 10.8349\n",
            "Epoch 262/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2766 - mae: 0.3114 - val_loss: 173.2127 - val_mae: 11.0181\n",
            "Epoch 263/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3271 - mae: 0.3860 - val_loss: 182.5343 - val_mae: 11.2546\n",
            "Epoch 264/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6467 - mae: 0.6542 - val_loss: 168.7543 - val_mae: 10.9260\n",
            "Epoch 265/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.9469 - mae: 0.6768 - val_loss: 165.7854 - val_mae: 10.8327\n",
            "Epoch 266/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5643 - mae: 0.5735 - val_loss: 174.8736 - val_mae: 11.1900\n",
            "Epoch 267/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.7888 - mae: 0.6721 - val_loss: 177.4346 - val_mae: 11.2068\n",
            "Epoch 268/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.4460 - mae: 0.4189 - val_loss: 150.4862 - val_mae: 10.4742\n",
            "Epoch 269/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5013 - mae: 0.5805 - val_loss: 162.2719 - val_mae: 10.7611\n",
            "Epoch 270/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3203 - mae: 0.3926 - val_loss: 166.2222 - val_mae: 10.8256\n",
            "Epoch 271/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3524 - mae: 0.4366 - val_loss: 180.0195 - val_mae: 11.1129\n",
            "Epoch 272/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2151 - mae: 0.2991 - val_loss: 174.5361 - val_mae: 10.9878\n",
            "Epoch 273/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2041 - mae: 0.2581 - val_loss: 183.3797 - val_mae: 11.2118\n",
            "Epoch 274/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2013 - mae: 0.2712 - val_loss: 192.2146 - val_mae: 11.4280\n",
            "Epoch 275/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1915 - mae: 0.2664 - val_loss: 190.3405 - val_mae: 11.3821\n",
            "Epoch 276/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1851 - mae: 0.2725 - val_loss: 183.9666 - val_mae: 11.2495\n",
            "Epoch 277/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2130 - mae: 0.3010 - val_loss: 182.4223 - val_mae: 11.2263\n",
            "Epoch 278/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1832 - mae: 0.2608 - val_loss: 192.1582 - val_mae: 11.4779\n",
            "Epoch 279/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1925 - mae: 0.2793 - val_loss: 200.9532 - val_mae: 11.6788\n",
            "Epoch 280/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.2120 - mae: 0.2858 - val_loss: 194.7186 - val_mae: 11.5097\n",
            "Epoch 281/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.2016 - mae: 0.3005 - val_loss: 194.5878 - val_mae: 11.4716\n",
            "Epoch 282/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2594 - mae: 0.3425 - val_loss: 191.6520 - val_mae: 11.3962\n",
            "Epoch 283/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.2521 - mae: 0.3456 - val_loss: 193.5402 - val_mae: 11.4254\n",
            "Epoch 284/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.2482 - mae: 0.3475 - val_loss: 192.8101 - val_mae: 11.3856\n",
            "Epoch 285/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3774 - mae: 0.4318 - val_loss: 188.8202 - val_mae: 11.2849\n",
            "Epoch 286/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2294 - mae: 0.3331 - val_loss: 182.8248 - val_mae: 11.1640\n",
            "Epoch 287/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3996 - mae: 0.4577 - val_loss: 196.4431 - val_mae: 11.4889\n",
            "Epoch 288/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3368 - mae: 0.4324 - val_loss: 199.4741 - val_mae: 11.5883\n",
            "Epoch 289/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.2508 - mae: 0.3476 - val_loss: 172.8539 - val_mae: 10.9572\n",
            "Epoch 290/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5790 - mae: 0.6208 - val_loss: 207.6281 - val_mae: 11.7739\n",
            "Epoch 291/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.8860 - mae: 0.7364 - val_loss: 218.4870 - val_mae: 11.9508\n",
            "Epoch 292/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.7908 - mae: 0.6803 - val_loss: 199.2106 - val_mae: 11.5314\n",
            "Epoch 293/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.9409 - mae: 0.7196 - val_loss: 216.5135 - val_mae: 11.9669\n",
            "Epoch 294/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 1.0649 - mae: 0.8660 - val_loss: 264.1932 - val_mae: 12.8369\n",
            "Epoch 295/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.8025 - mae: 0.6334 - val_loss: 252.4214 - val_mae: 12.4931\n",
            "Epoch 296/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.7396 - mae: 0.6530 - val_loss: 213.6667 - val_mae: 11.7480\n",
            "Epoch 297/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4725 - mae: 0.4215 - val_loss: 229.5519 - val_mae: 12.1286\n",
            "Epoch 298/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2450 - mae: 0.3419 - val_loss: 230.1143 - val_mae: 12.1771\n",
            "Epoch 299/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2550 - mae: 0.3353 - val_loss: 231.6312 - val_mae: 12.2569\n",
            "Epoch 300/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2503 - mae: 0.3457 - val_loss: 226.9795 - val_mae: 12.1775\n",
            "Epoch 301/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.2155 - mae: 0.3241 - val_loss: 226.1066 - val_mae: 12.1236\n",
            "Epoch 302/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1923 - mae: 0.2940 - val_loss: 225.6416 - val_mae: 12.1196\n",
            "Epoch 303/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2328 - mae: 0.3622 - val_loss: 234.3024 - val_mae: 12.3503\n",
            "Epoch 304/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1638 - mae: 0.2682 - val_loss: 238.9609 - val_mae: 12.4591\n",
            "Epoch 305/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.2025 - mae: 0.3239 - val_loss: 234.5164 - val_mae: 12.3706\n",
            "Epoch 306/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1849 - mae: 0.3105 - val_loss: 223.6643 - val_mae: 12.1565\n",
            "Epoch 307/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2071 - mae: 0.3325 - val_loss: 217.5773 - val_mae: 12.0152\n",
            "Epoch 308/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.2104 - mae: 0.3453 - val_loss: 233.8653 - val_mae: 12.3339\n",
            "Epoch 309/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3034 - mae: 0.4347 - val_loss: 233.3266 - val_mae: 12.3102\n",
            "Epoch 310/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4984 - mae: 0.5202 - val_loss: 219.1036 - val_mae: 11.9956\n",
            "Epoch 311/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6937 - mae: 0.6382 - val_loss: 192.6508 - val_mae: 11.4093\n",
            "Epoch 312/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.4884 - mae: 1.3382 - val_loss: 250.9832 - val_mae: 12.6020\n",
            "Epoch 313/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.5949 - mae: 1.2542 - val_loss: 238.7643 - val_mae: 12.3045\n",
            "Epoch 314/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 2.2596 - mae: 1.2031 - val_loss: 154.9918 - val_mae: 10.3506\n",
            "Epoch 315/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.8351 - mae: 1.2795 - val_loss: 221.9271 - val_mae: 12.0284\n",
            "Epoch 316/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.0605 - mae: 1.2315 - val_loss: 231.2342 - val_mae: 12.0821\n",
            "Epoch 317/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.7383 - mae: 1.2807 - val_loss: 194.2125 - val_mae: 11.3366\n",
            "Epoch 318/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.5479 - mae: 0.8826 - val_loss: 295.8492 - val_mae: 13.4188\n",
            "Epoch 319/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2547 - mae: 0.8017 - val_loss: 250.6732 - val_mae: 12.6818\n",
            "Epoch 320/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.7851 - mae: 1.2717 - val_loss: 166.0992 - val_mae: 10.7890\n",
            "Epoch 321/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.2113 - mae: 2.6861 - val_loss: 236.2309 - val_mae: 12.5712\n",
            "Epoch 322/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 10.1443 - mae: 2.1955 - val_loss: 179.0988 - val_mae: 11.4645\n",
            "Epoch 323/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 4.1902 - mae: 1.6322 - val_loss: 107.7614 - val_mae: 9.5010\n",
            "Epoch 324/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 12.0739 - mae: 2.6059 - val_loss: 103.2034 - val_mae: 9.2595\n",
            "Epoch 325/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 6.7933 - mae: 1.9216 - val_loss: 97.7563 - val_mae: 8.8511\n",
            "Epoch 326/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.3954 - mae: 1.6702 - val_loss: 91.2647 - val_mae: 8.6985\n",
            "Epoch 327/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 4.0128 - mae: 1.6353 - val_loss: 115.2663 - val_mae: 9.3349\n",
            "Epoch 328/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 3.7051 - mae: 1.6960 - val_loss: 77.2734 - val_mae: 8.0056\n",
            "Epoch 329/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 3.0001 - mae: 1.3926 - val_loss: 118.5629 - val_mae: 9.3572\n",
            "Epoch 330/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 3.1827 - mae: 1.5526 - val_loss: 82.2645 - val_mae: 8.2419\n",
            "Epoch 331/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 4.8424 - mae: 1.7881 - val_loss: 123.5094 - val_mae: 9.5134\n",
            "Epoch 332/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 3.2985 - mae: 1.4898 - val_loss: 88.2327 - val_mae: 8.5102\n",
            "Epoch 333/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 2.9275 - mae: 1.3234 - val_loss: 132.4742 - val_mae: 10.0104\n",
            "Epoch 334/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 2.0638 - mae: 1.1864 - val_loss: 106.6725 - val_mae: 9.2477\n",
            "Epoch 335/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 3.2665 - mae: 1.4255 - val_loss: 138.1736 - val_mae: 10.0339\n",
            "Epoch 336/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.1606 - mae: 1.2196 - val_loss: 126.4557 - val_mae: 9.6527\n",
            "Epoch 337/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 3.1332 - mae: 1.4085 - val_loss: 190.5713 - val_mae: 11.3162\n",
            "Epoch 338/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.7125 - mae: 1.5126 - val_loss: 177.5955 - val_mae: 11.2208\n",
            "Epoch 339/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 4.6049 - mae: 1.4208 - val_loss: 177.0983 - val_mae: 11.2855\n",
            "Epoch 340/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.8960 - mae: 1.1371 - val_loss: 150.7946 - val_mae: 10.5018\n",
            "Epoch 341/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0144 - mae: 0.7584 - val_loss: 146.3457 - val_mae: 10.2718\n",
            "Epoch 342/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5779 - mae: 1.0385 - val_loss: 160.1700 - val_mae: 10.7424\n",
            "Epoch 343/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.6600 - mae: 0.6339 - val_loss: 164.3592 - val_mae: 10.9472\n",
            "Epoch 344/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0631 - mae: 0.8788 - val_loss: 162.9050 - val_mae: 10.8767\n",
            "Epoch 345/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.8581 - mae: 0.7306 - val_loss: 146.4579 - val_mae: 10.3500\n",
            "Epoch 346/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5511 - mae: 0.5773 - val_loss: 146.6852 - val_mae: 10.2759\n",
            "Epoch 347/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3319 - mae: 0.4725 - val_loss: 148.8087 - val_mae: 10.3589\n",
            "Epoch 348/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2302 - mae: 0.3304 - val_loss: 158.6323 - val_mae: 10.6524\n",
            "Epoch 349/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2020 - mae: 0.3226 - val_loss: 159.6486 - val_mae: 10.6798\n",
            "Epoch 350/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1577 - mae: 0.2556 - val_loss: 157.9520 - val_mae: 10.6099\n",
            "Epoch 351/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1414 - mae: 0.2501 - val_loss: 158.1543 - val_mae: 10.6151\n",
            "Epoch 352/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1192 - mae: 0.2119 - val_loss: 163.4659 - val_mae: 10.7853\n",
            "Epoch 353/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1037 - mae: 0.1860 - val_loss: 164.3110 - val_mae: 10.8267\n",
            "Epoch 354/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0994 - mae: 0.1710 - val_loss: 166.7544 - val_mae: 10.8813\n",
            "Epoch 355/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0928 - mae: 0.1664 - val_loss: 165.0915 - val_mae: 10.8442\n",
            "Epoch 356/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0939 - mae: 0.1664 - val_loss: 167.9410 - val_mae: 10.9166\n",
            "Epoch 357/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0866 - mae: 0.1484 - val_loss: 167.3728 - val_mae: 10.9152\n",
            "Epoch 358/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0825 - mae: 0.1436 - val_loss: 169.6144 - val_mae: 10.9641\n",
            "Epoch 359/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0785 - mae: 0.1348 - val_loss: 169.6462 - val_mae: 10.9540\n",
            "Epoch 360/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0777 - mae: 0.1330 - val_loss: 170.8980 - val_mae: 10.9842\n",
            "Epoch 361/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0733 - mae: 0.1206 - val_loss: 170.7283 - val_mae: 10.9889\n",
            "Epoch 362/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0701 - mae: 0.1071 - val_loss: 171.0888 - val_mae: 11.0064\n",
            "Epoch 363/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0680 - mae: 0.1027 - val_loss: 169.2314 - val_mae: 10.9679\n",
            "Epoch 364/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0658 - mae: 0.1023 - val_loss: 169.7408 - val_mae: 10.9841\n",
            "Epoch 365/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0651 - mae: 0.1051 - val_loss: 169.6868 - val_mae: 10.9957\n",
            "Epoch 366/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0618 - mae: 0.0960 - val_loss: 170.1741 - val_mae: 11.0093\n",
            "Epoch 367/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0609 - mae: 0.0956 - val_loss: 170.3978 - val_mae: 11.0134\n",
            "Epoch 368/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0591 - mae: 0.0940 - val_loss: 171.3572 - val_mae: 11.0389\n",
            "Epoch 369/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0581 - mae: 0.0954 - val_loss: 173.8436 - val_mae: 11.1166\n",
            "Epoch 370/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0544 - mae: 0.0935 - val_loss: 174.8042 - val_mae: 11.1507\n",
            "Epoch 371/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0520 - mae: 0.0852 - val_loss: 174.4347 - val_mae: 11.1502\n",
            "Epoch 372/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0506 - mae: 0.0868 - val_loss: 177.6997 - val_mae: 11.2181\n",
            "Epoch 373/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0486 - mae: 0.0836 - val_loss: 180.0170 - val_mae: 11.2812\n",
            "Epoch 374/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0492 - mae: 0.0853 - val_loss: 181.5093 - val_mae: 11.3210\n",
            "Epoch 375/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0459 - mae: 0.0761 - val_loss: 179.5885 - val_mae: 11.2715\n",
            "Epoch 376/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0474 - mae: 0.0976 - val_loss: 178.3221 - val_mae: 11.2438\n",
            "Epoch 377/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0454 - mae: 0.0902 - val_loss: 177.7612 - val_mae: 11.2403\n",
            "Epoch 378/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0429 - mae: 0.0892 - val_loss: 176.3099 - val_mae: 11.2165\n",
            "Epoch 379/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0424 - mae: 0.0877 - val_loss: 177.8193 - val_mae: 11.2568\n",
            "Epoch 380/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0391 - mae: 0.0763 - val_loss: 177.9613 - val_mae: 11.2641\n",
            "Epoch 381/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0382 - mae: 0.0758 - val_loss: 178.8270 - val_mae: 11.2879\n",
            "Epoch 382/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0368 - mae: 0.0722 - val_loss: 179.1905 - val_mae: 11.2966\n",
            "Epoch 383/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0349 - mae: 0.0633 - val_loss: 180.3613 - val_mae: 11.3266\n",
            "Epoch 384/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0339 - mae: 0.0681 - val_loss: 179.5414 - val_mae: 11.3127\n",
            "Epoch 385/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0328 - mae: 0.0636 - val_loss: 179.7392 - val_mae: 11.3183\n",
            "Epoch 386/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0318 - mae: 0.0594 - val_loss: 181.0636 - val_mae: 11.3481\n",
            "Epoch 387/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0312 - mae: 0.0592 - val_loss: 182.1084 - val_mae: 11.3741\n",
            "Epoch 388/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0303 - mae: 0.0577 - val_loss: 182.9681 - val_mae: 11.3956\n",
            "Epoch 389/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0298 - mae: 0.0550 - val_loss: 182.5198 - val_mae: 11.3894\n",
            "Epoch 390/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0285 - mae: 0.0533 - val_loss: 183.1828 - val_mae: 11.4057\n",
            "Epoch 391/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0277 - mae: 0.0515 - val_loss: 183.5329 - val_mae: 11.4165\n",
            "Epoch 392/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0270 - mae: 0.0525 - val_loss: 184.1607 - val_mae: 11.4321\n",
            "Epoch 393/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0264 - mae: 0.0558 - val_loss: 185.3930 - val_mae: 11.4570\n",
            "Epoch 394/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0254 - mae: 0.0570 - val_loss: 185.6400 - val_mae: 11.4625\n",
            "Epoch 395/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0247 - mae: 0.0521 - val_loss: 187.4517 - val_mae: 11.5035\n",
            "Epoch 396/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0242 - mae: 0.0516 - val_loss: 187.5612 - val_mae: 11.5097\n",
            "Epoch 397/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0235 - mae: 0.0500 - val_loss: 188.3034 - val_mae: 11.5279\n",
            "Epoch 398/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0228 - mae: 0.0510 - val_loss: 187.9124 - val_mae: 11.5218\n",
            "Epoch 399/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0221 - mae: 0.0477 - val_loss: 188.8259 - val_mae: 11.5413\n",
            "Epoch 400/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0216 - mae: 0.0476 - val_loss: 189.5408 - val_mae: 11.5580\n",
            "Epoch 401/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0211 - mae: 0.0464 - val_loss: 189.1992 - val_mae: 11.5555\n",
            "Epoch 402/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0207 - mae: 0.0467 - val_loss: 189.0312 - val_mae: 11.5543\n",
            "Epoch 403/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0200 - mae: 0.0481 - val_loss: 192.5177 - val_mae: 11.6245\n",
            "Epoch 404/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0189 - mae: 0.0430 - val_loss: 193.8992 - val_mae: 11.6520\n",
            "Epoch 405/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0184 - mae: 0.0423 - val_loss: 195.9141 - val_mae: 11.6939\n",
            "Epoch 406/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0182 - mae: 0.0436 - val_loss: 196.4113 - val_mae: 11.7039\n",
            "Epoch 407/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0175 - mae: 0.0436 - val_loss: 196.8447 - val_mae: 11.7142\n",
            "Epoch 408/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0170 - mae: 0.0438 - val_loss: 198.0205 - val_mae: 11.7480\n",
            "Epoch 409/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0171 - mae: 0.0506 - val_loss: 198.2960 - val_mae: 11.7594\n",
            "Epoch 410/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0164 - mae: 0.0476 - val_loss: 199.6238 - val_mae: 11.7875\n",
            "Epoch 411/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0157 - mae: 0.0411 - val_loss: 199.0726 - val_mae: 11.7777\n",
            "Epoch 412/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0153 - mae: 0.0402 - val_loss: 199.3341 - val_mae: 11.7846\n",
            "Epoch 413/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0149 - mae: 0.0401 - val_loss: 199.1186 - val_mae: 11.7830\n",
            "Epoch 414/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0145 - mae: 0.0408 - val_loss: 198.9360 - val_mae: 11.7844\n",
            "Epoch 415/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0143 - mae: 0.0413 - val_loss: 200.0784 - val_mae: 11.8124\n",
            "Epoch 416/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0140 - mae: 0.0413 - val_loss: 199.4597 - val_mae: 11.8008\n",
            "Epoch 417/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0134 - mae: 0.0378 - val_loss: 200.2879 - val_mae: 11.8191\n",
            "Epoch 418/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0131 - mae: 0.0391 - val_loss: 199.7535 - val_mae: 11.8111\n",
            "Epoch 419/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0128 - mae: 0.0341 - val_loss: 200.3622 - val_mae: 11.8279\n",
            "Epoch 420/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0122 - mae: 0.0339 - val_loss: 202.1283 - val_mae: 11.8652\n",
            "Epoch 421/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0120 - mae: 0.0328 - val_loss: 202.9250 - val_mae: 11.8819\n",
            "Epoch 422/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0116 - mae: 0.0309 - val_loss: 203.2011 - val_mae: 11.8876\n",
            "Epoch 423/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0114 - mae: 0.0321 - val_loss: 203.3935 - val_mae: 11.8975\n",
            "Epoch 424/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0109 - mae: 0.0322 - val_loss: 204.2099 - val_mae: 11.9177\n",
            "Epoch 425/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0108 - mae: 0.0330 - val_loss: 204.3589 - val_mae: 11.9225\n",
            "Epoch 426/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0105 - mae: 0.0343 - val_loss: 205.3198 - val_mae: 11.9447\n",
            "Epoch 427/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0101 - mae: 0.0319 - val_loss: 205.5070 - val_mae: 11.9503\n",
            "Epoch 428/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0098 - mae: 0.0316 - val_loss: 205.5836 - val_mae: 11.9539\n",
            "Epoch 429/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0095 - mae: 0.0313 - val_loss: 205.2947 - val_mae: 11.9490\n",
            "Epoch 430/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0092 - mae: 0.0288 - val_loss: 206.9189 - val_mae: 11.9837\n",
            "Epoch 431/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0088 - mae: 0.0287 - val_loss: 208.0608 - val_mae: 12.0086\n",
            "Epoch 432/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0086 - mae: 0.0290 - val_loss: 208.1688 - val_mae: 12.0148\n",
            "Epoch 433/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0084 - mae: 0.0309 - val_loss: 208.5281 - val_mae: 12.0245\n",
            "Epoch 434/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0082 - mae: 0.0301 - val_loss: 208.0511 - val_mae: 12.0164\n",
            "Epoch 435/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0077 - mae: 0.0257 - val_loss: 209.9332 - val_mae: 12.0551\n",
            "Epoch 436/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0075 - mae: 0.0266 - val_loss: 210.3505 - val_mae: 12.0634\n",
            "Epoch 437/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0074 - mae: 0.0268 - val_loss: 210.7309 - val_mae: 12.0697\n",
            "Epoch 438/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0071 - mae: 0.0283 - val_loss: 210.7788 - val_mae: 12.0697\n",
            "Epoch 439/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0069 - mae: 0.0264 - val_loss: 211.7814 - val_mae: 12.0909\n",
            "Epoch 440/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0068 - mae: 0.0267 - val_loss: 212.4725 - val_mae: 12.1070\n",
            "Epoch 441/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0065 - mae: 0.0239 - val_loss: 212.6839 - val_mae: 12.1132\n",
            "Epoch 442/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0062 - mae: 0.0235 - val_loss: 213.4363 - val_mae: 12.1320\n",
            "Epoch 443/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0061 - mae: 0.0253 - val_loss: 213.6384 - val_mae: 12.1390\n",
            "Epoch 444/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0061 - mae: 0.0269 - val_loss: 214.1296 - val_mae: 12.1496\n",
            "Epoch 445/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0058 - mae: 0.0258 - val_loss: 214.0804 - val_mae: 12.1507\n",
            "Epoch 446/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0055 - mae: 0.0229 - val_loss: 214.4341 - val_mae: 12.1594\n",
            "Epoch 447/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0054 - mae: 0.0222 - val_loss: 214.3934 - val_mae: 12.1598\n",
            "Epoch 448/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0052 - mae: 0.0225 - val_loss: 215.5599 - val_mae: 12.1820\n",
            "Epoch 449/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0050 - mae: 0.0212 - val_loss: 216.1133 - val_mae: 12.1940\n",
            "Epoch 450/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0049 - mae: 0.0224 - val_loss: 216.0596 - val_mae: 12.1943\n",
            "Epoch 451/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0047 - mae: 0.0212 - val_loss: 216.0368 - val_mae: 12.1954\n",
            "Epoch 452/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0045 - mae: 0.0211 - val_loss: 215.8579 - val_mae: 12.1926\n",
            "Epoch 453/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0045 - mae: 0.0208 - val_loss: 216.7459 - val_mae: 12.2115\n",
            "Epoch 454/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0042 - mae: 0.0205 - val_loss: 218.3410 - val_mae: 12.2440\n",
            "Epoch 455/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0042 - mae: 0.0223 - val_loss: 219.4143 - val_mae: 12.2650\n",
            "Epoch 456/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0040 - mae: 0.0214 - val_loss: 218.9565 - val_mae: 12.2552\n",
            "Epoch 457/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0040 - mae: 0.0250 - val_loss: 219.5444 - val_mae: 12.2691\n",
            "Epoch 458/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0038 - mae: 0.0227 - val_loss: 219.2748 - val_mae: 12.2662\n",
            "Epoch 459/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0037 - mae: 0.0233 - val_loss: 219.2483 - val_mae: 12.2682\n",
            "Epoch 460/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0037 - mae: 0.0256 - val_loss: 220.4656 - val_mae: 12.2949\n",
            "Epoch 461/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0037 - mae: 0.0300 - val_loss: 221.0528 - val_mae: 12.3088\n",
            "Epoch 462/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0038 - mae: 0.0303 - val_loss: 221.5659 - val_mae: 12.3201\n",
            "Epoch 463/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0048 - mae: 0.0416 - val_loss: 222.7744 - val_mae: 12.3450\n",
            "Epoch 464/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0040 - mae: 0.0376 - val_loss: 221.1275 - val_mae: 12.3170\n",
            "Epoch 465/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0042 - mae: 0.0383 - val_loss: 221.4592 - val_mae: 12.3207\n",
            "Epoch 466/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0035 - mae: 0.0315 - val_loss: 221.2518 - val_mae: 12.3111\n",
            "Epoch 467/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0032 - mae: 0.0274 - val_loss: 221.9861 - val_mae: 12.3244\n",
            "Epoch 468/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0031 - mae: 0.0270 - val_loss: 223.0482 - val_mae: 12.3485\n",
            "Epoch 469/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0028 - mae: 0.0227 - val_loss: 222.8168 - val_mae: 12.3474\n",
            "Epoch 470/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0028 - mae: 0.0244 - val_loss: 223.6660 - val_mae: 12.3639\n",
            "Epoch 471/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0030 - mae: 0.0279 - val_loss: 222.9359 - val_mae: 12.3466\n",
            "Epoch 472/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0029 - mae: 0.0300 - val_loss: 221.9175 - val_mae: 12.3274\n",
            "Epoch 473/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0025 - mae: 0.0230 - val_loss: 223.9943 - val_mae: 12.3712\n",
            "Epoch 474/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0023 - mae: 0.0222 - val_loss: 223.6065 - val_mae: 12.3634\n",
            "Epoch 475/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0024 - mae: 0.0244 - val_loss: 224.1414 - val_mae: 12.3715\n",
            "Epoch 476/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0024 - mae: 0.0233 - val_loss: 223.5112 - val_mae: 12.3554\n",
            "Epoch 477/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0025 - mae: 0.0280 - val_loss: 223.4293 - val_mae: 12.3570\n",
            "Epoch 478/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0026 - mae: 0.0286 - val_loss: 224.8380 - val_mae: 12.3870\n",
            "Epoch 479/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0025 - mae: 0.0299 - val_loss: 225.2210 - val_mae: 12.3942\n",
            "Epoch 480/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0027 - mae: 0.0280 - val_loss: 224.2753 - val_mae: 12.3777\n",
            "Epoch 481/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0031 - mae: 0.0328 - val_loss: 225.0882 - val_mae: 12.3931\n",
            "Epoch 482/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0022 - mae: 0.0268 - val_loss: 224.6072 - val_mae: 12.3823\n",
            "Epoch 483/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0020 - mae: 0.0247 - val_loss: 225.5620 - val_mae: 12.4019\n",
            "Epoch 484/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0021 - mae: 0.0255 - val_loss: 225.9587 - val_mae: 12.4130\n",
            "Epoch 485/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0018 - mae: 0.0232 - val_loss: 225.6636 - val_mae: 12.4083\n",
            "Epoch 486/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0018 - mae: 0.0243 - val_loss: 227.0178 - val_mae: 12.4328\n",
            "Epoch 487/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0016 - mae: 0.0214 - val_loss: 227.3988 - val_mae: 12.4415\n",
            "Epoch 488/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0014 - mae: 0.0170 - val_loss: 227.3678 - val_mae: 12.4408\n",
            "Epoch 489/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0014 - mae: 0.0171 - val_loss: 227.3990 - val_mae: 12.4404\n",
            "Epoch 490/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0013 - mae: 0.0154 - val_loss: 226.9994 - val_mae: 12.4329\n",
            "Epoch 491/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0012 - mae: 0.0150 - val_loss: 227.6383 - val_mae: 12.4478\n",
            "Epoch 492/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0012 - mae: 0.0152 - val_loss: 228.3334 - val_mae: 12.4619\n",
            "Epoch 493/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0011 - mae: 0.0138 - val_loss: 229.0903 - val_mae: 12.4756\n",
            "Epoch 494/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0012 - mae: 0.0180 - val_loss: 228.9619 - val_mae: 12.4742\n",
            "Epoch 495/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0011 - mae: 0.0157 - val_loss: 229.1548 - val_mae: 12.4788\n",
            "Epoch 496/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0011 - mae: 0.0164 - val_loss: 229.1653 - val_mae: 12.4784\n",
            "Epoch 497/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0011 - mae: 0.0189 - val_loss: 228.6582 - val_mae: 12.4689\n",
            "Epoch 498/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0011 - mae: 0.0198 - val_loss: 229.7352 - val_mae: 12.4907\n",
            "Epoch 499/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 9.6722e-04 - mae: 0.0164 - val_loss: 229.5623 - val_mae: 12.4884\n",
            "Epoch 500/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 9.8529e-04 - mae: 0.0177 - val_loss: 229.1848 - val_mae: 12.4790\n",
            "Epoch 501/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 8.6665e-04 - mae: 0.0146 - val_loss: 230.0573 - val_mae: 12.4958\n",
            "Epoch 502/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 8.5648e-04 - mae: 0.0153 - val_loss: 230.6079 - val_mae: 12.5102\n",
            "Epoch 503/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 7.3682e-04 - mae: 0.0125 - val_loss: 230.8639 - val_mae: 12.5141\n",
            "Epoch 504/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 6.7928e-04 - mae: 0.0113 - val_loss: 230.8710 - val_mae: 12.5132\n",
            "Epoch 505/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 6.6257e-04 - mae: 0.0100 - val_loss: 230.9342 - val_mae: 12.5155\n",
            "Epoch 506/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 6.1080e-04 - mae: 0.0098 - val_loss: 231.0672 - val_mae: 12.5192\n",
            "Epoch 507/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 6.0584e-04 - mae: 0.0111 - val_loss: 231.1083 - val_mae: 12.5201\n",
            "Epoch 508/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 5.8814e-04 - mae: 0.0112 - val_loss: 231.5879 - val_mae: 12.5297\n",
            "Epoch 509/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 5.5621e-04 - mae: 0.0110 - val_loss: 231.4352 - val_mae: 12.5275\n",
            "Epoch 510/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 5.4648e-04 - mae: 0.0108 - val_loss: 231.4908 - val_mae: 12.5282\n",
            "Epoch 511/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 4.8949e-04 - mae: 0.0081 - val_loss: 231.7142 - val_mae: 12.5308\n",
            "Epoch 512/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 4.7278e-04 - mae: 0.0079 - val_loss: 232.1263 - val_mae: 12.5385\n",
            "Epoch 513/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 4.4669e-04 - mae: 0.0075 - val_loss: 232.3399 - val_mae: 12.5432\n",
            "Epoch 514/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 4.2881e-04 - mae: 0.0068 - val_loss: 232.2512 - val_mae: 12.5422\n",
            "Epoch 515/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 4.1828e-04 - mae: 0.0072 - val_loss: 232.1081 - val_mae: 12.5411\n",
            "Epoch 516/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 4.2180e-04 - mae: 0.0078 - val_loss: 232.4119 - val_mae: 12.5469\n",
            "Epoch 517/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 4.1425e-04 - mae: 0.0096 - val_loss: 233.4331 - val_mae: 12.5651\n",
            "Epoch 518/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 3.8700e-04 - mae: 0.0084 - val_loss: 234.1135 - val_mae: 12.5766\n",
            "Epoch 519/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 3.7320e-04 - mae: 0.0084 - val_loss: 234.2400 - val_mae: 12.5776\n",
            "Epoch 520/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 3.4992e-04 - mae: 0.0078 - val_loss: 234.2228 - val_mae: 12.5779\n",
            "Epoch 521/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 3.5916e-04 - mae: 0.0089 - val_loss: 234.5033 - val_mae: 12.5842\n",
            "Epoch 522/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 3.1586e-04 - mae: 0.0073 - val_loss: 234.6779 - val_mae: 12.5881\n",
            "Epoch 523/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 3.2158e-04 - mae: 0.0089 - val_loss: 234.5034 - val_mae: 12.5851\n",
            "Epoch 524/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 2.8514e-04 - mae: 0.0069 - val_loss: 234.4209 - val_mae: 12.5841\n",
            "Epoch 525/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 2.6089e-04 - mae: 0.0058 - val_loss: 234.1166 - val_mae: 12.5793\n",
            "Epoch 526/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 2.5188e-04 - mae: 0.0062 - val_loss: 234.0580 - val_mae: 12.5790\n",
            "Epoch 527/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 2.3683e-04 - mae: 0.0059 - val_loss: 234.0396 - val_mae: 12.5793\n",
            "Epoch 528/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 2.4115e-04 - mae: 0.0064 - val_loss: 234.3818 - val_mae: 12.5859\n",
            "Epoch 529/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 2.1407e-04 - mae: 0.0055 - val_loss: 234.3661 - val_mae: 12.5853\n",
            "Epoch 530/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 2.0739e-04 - mae: 0.0056 - val_loss: 234.3241 - val_mae: 12.5851\n",
            "Epoch 531/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.9951e-04 - mae: 0.0055 - val_loss: 234.5225 - val_mae: 12.5892\n",
            "Epoch 532/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.9232e-04 - mae: 0.0058 - val_loss: 234.4845 - val_mae: 12.5885\n",
            "Epoch 533/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8878e-04 - mae: 0.0059 - val_loss: 234.4749 - val_mae: 12.5881\n",
            "Epoch 534/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.7817e-04 - mae: 0.0056 - val_loss: 234.9434 - val_mae: 12.5970\n",
            "Epoch 535/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.6363e-04 - mae: 0.0052 - val_loss: 234.7302 - val_mae: 12.5930\n",
            "Epoch 536/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.6427e-04 - mae: 0.0053 - val_loss: 234.8677 - val_mae: 12.5960\n",
            "Epoch 537/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.5217e-04 - mae: 0.0047 - val_loss: 235.0814 - val_mae: 12.5998\n",
            "Epoch 538/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.4105e-04 - mae: 0.0045 - val_loss: 235.1351 - val_mae: 12.6007\n",
            "Epoch 539/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3709e-04 - mae: 0.0044 - val_loss: 235.2750 - val_mae: 12.6042\n",
            "Epoch 540/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.3488e-04 - mae: 0.0048 - val_loss: 235.3103 - val_mae: 12.6052\n",
            "Epoch 541/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.2192e-04 - mae: 0.0036 - val_loss: 235.0770 - val_mae: 12.6004\n",
            "Epoch 542/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.2146e-04 - mae: 0.0038 - val_loss: 235.1602 - val_mae: 12.6018\n",
            "Epoch 543/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.1366e-04 - mae: 0.0039 - val_loss: 235.6159 - val_mae: 12.6101\n",
            "Epoch 544/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.0782e-04 - mae: 0.0033 - val_loss: 236.0681 - val_mae: 12.6186\n",
            "Epoch 545/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.0371e-04 - mae: 0.0036 - val_loss: 236.3296 - val_mae: 12.6235\n",
            "Epoch 546/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0091e-04 - mae: 0.0036 - val_loss: 236.2868 - val_mae: 12.6228\n",
            "Epoch 547/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 9.5777e-05 - mae: 0.0033 - val_loss: 236.3093 - val_mae: 12.6236\n",
            "Epoch 548/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 9.1032e-05 - mae: 0.0035 - val_loss: 236.3313 - val_mae: 12.6242\n",
            "Epoch 549/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 8.8469e-05 - mae: 0.0033 - val_loss: 236.2762 - val_mae: 12.6233\n",
            "Epoch 550/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 8.4151e-05 - mae: 0.0031 - val_loss: 236.4819 - val_mae: 12.6274\n",
            "Epoch 551/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 7.9530e-05 - mae: 0.0034 - val_loss: 236.4087 - val_mae: 12.6263\n",
            "Epoch 552/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 7.4988e-05 - mae: 0.0030 - val_loss: 236.4408 - val_mae: 12.6270\n",
            "Epoch 553/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 7.1868e-05 - mae: 0.0030 - val_loss: 236.6203 - val_mae: 12.6306\n",
            "Epoch 554/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.2643e-05 - mae: 0.0034 - val_loss: 236.6144 - val_mae: 12.6307\n",
            "Epoch 555/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 6.6916e-05 - mae: 0.0032 - val_loss: 236.6178 - val_mae: 12.6306\n",
            "Epoch 556/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 6.2677e-05 - mae: 0.0030 - val_loss: 236.5732 - val_mae: 12.6302\n",
            "Epoch 557/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 5.8767e-05 - mae: 0.0028 - val_loss: 236.5559 - val_mae: 12.6301\n",
            "Epoch 558/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 5.7361e-05 - mae: 0.0030 - val_loss: 236.5398 - val_mae: 12.6297\n",
            "Epoch 559/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 5.5064e-05 - mae: 0.0028 - val_loss: 236.5666 - val_mae: 12.6303\n",
            "Epoch 560/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 5.3947e-05 - mae: 0.0032 - val_loss: 236.6932 - val_mae: 12.6330\n",
            "Epoch 561/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 5.2642e-05 - mae: 0.0032 - val_loss: 236.9322 - val_mae: 12.6376\n",
            "Epoch 562/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 5.1097e-05 - mae: 0.0033 - val_loss: 236.8413 - val_mae: 12.6356\n",
            "Epoch 563/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.7537e-05 - mae: 0.0029 - val_loss: 236.9169 - val_mae: 12.6371\n",
            "Epoch 564/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.4283e-05 - mae: 0.0025 - val_loss: 236.9283 - val_mae: 12.6375\n",
            "Epoch 565/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.1421e-05 - mae: 0.0022 - val_loss: 236.8726 - val_mae: 12.6364\n",
            "Epoch 566/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 3.9493e-05 - mae: 0.0021 - val_loss: 236.9326 - val_mae: 12.6376\n",
            "Epoch 567/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 3.7726e-05 - mae: 0.0022 - val_loss: 237.0089 - val_mae: 12.6390\n",
            "Epoch 568/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 3.5329e-05 - mae: 0.0020 - val_loss: 237.1618 - val_mae: 12.6420\n",
            "Epoch 569/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 3.3687e-05 - mae: 0.0019 - val_loss: 237.2780 - val_mae: 12.6445\n",
            "Epoch 570/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 3.2642e-05 - mae: 0.0019 - val_loss: 237.2525 - val_mae: 12.6440\n",
            "Epoch 571/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 3.1897e-05 - mae: 0.0020 - val_loss: 237.2412 - val_mae: 12.6438\n",
            "Epoch 572/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 3.3335e-05 - mae: 0.0026 - val_loss: 237.3104 - val_mae: 12.6454\n",
            "Epoch 573/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 3.0099e-05 - mae: 0.0021 - val_loss: 237.2922 - val_mae: 12.6451\n",
            "Epoch 574/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 3.3498e-05 - mae: 0.0027 - val_loss: 237.4052 - val_mae: 12.6472\n",
            "Epoch 575/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.0030e-05 - mae: 0.0027 - val_loss: 237.3813 - val_mae: 12.6467\n",
            "Epoch 576/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.0851e-05 - mae: 0.0029 - val_loss: 237.2285 - val_mae: 12.6438\n",
            "Epoch 577/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 2.6427e-05 - mae: 0.0024 - val_loss: 237.3433 - val_mae: 12.6460\n",
            "Epoch 578/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.4601e-05 - mae: 0.0022 - val_loss: 237.4274 - val_mae: 12.6475\n",
            "Epoch 579/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 2.6876e-05 - mae: 0.0028 - val_loss: 237.6307 - val_mae: 12.6517\n",
            "Epoch 580/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 2.5610e-05 - mae: 0.0029 - val_loss: 237.6617 - val_mae: 12.6526\n",
            "Epoch 581/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.4399e-05 - mae: 0.0026 - val_loss: 237.4930 - val_mae: 12.6490\n",
            "Epoch 582/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.4896e-05 - mae: 0.0030 - val_loss: 237.6064 - val_mae: 12.6511\n",
            "Epoch 583/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.9657e-05 - mae: 0.0020 - val_loss: 237.6462 - val_mae: 12.6521\n",
            "Epoch 584/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.9205e-05 - mae: 0.0020 - val_loss: 237.6779 - val_mae: 12.6527\n",
            "Epoch 585/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.7200e-05 - mae: 0.0019 - val_loss: 237.7809 - val_mae: 12.6549\n",
            "Epoch 586/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.6783e-05 - mae: 0.0020 - val_loss: 237.7344 - val_mae: 12.6542\n",
            "Epoch 587/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6248e-05 - mae: 0.0019 - val_loss: 237.7075 - val_mae: 12.6533\n",
            "Epoch 588/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.5945e-05 - mae: 0.0038 - val_loss: 237.7736 - val_mae: 12.6546\n",
            "Epoch 589/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 2.2425e-05 - mae: 0.0033 - val_loss: 237.8948 - val_mae: 12.6570\n",
            "Epoch 590/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.4067e-05 - mae: 0.0032 - val_loss: 237.8720 - val_mae: 12.6565\n",
            "Epoch 591/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 3.2590e-05 - mae: 0.0043 - val_loss: 238.0212 - val_mae: 12.6591\n",
            "Epoch 592/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.0705e-05 - mae: 0.0041 - val_loss: 237.9587 - val_mae: 12.6581\n",
            "Epoch 593/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.1730e-05 - mae: 0.0041 - val_loss: 237.7764 - val_mae: 12.6551\n",
            "Epoch 594/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.0889e-05 - mae: 0.0043 - val_loss: 237.6613 - val_mae: 12.6519\n",
            "Epoch 595/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 3.9019e-05 - mae: 0.0044 - val_loss: 237.8570 - val_mae: 12.6555\n",
            "Epoch 596/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.3456e-05 - mae: 0.0042 - val_loss: 237.8756 - val_mae: 12.6562\n",
            "Epoch 597/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 5.5886e-05 - mae: 0.0054 - val_loss: 237.9823 - val_mae: 12.6590\n",
            "Epoch 598/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 4.5229e-05 - mae: 0.0050 - val_loss: 238.0235 - val_mae: 12.6597\n",
            "Epoch 599/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 4.9494e-05 - mae: 0.0057 - val_loss: 237.9062 - val_mae: 12.6573\n",
            "Epoch 600/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 7.7273e-05 - mae: 0.0071 - val_loss: 237.9586 - val_mae: 12.6589\n",
            "Epoch 601/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 5.2388e-05 - mae: 0.0053 - val_loss: 237.8425 - val_mae: 12.6562\n",
            "Epoch 602/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 8.7518e-05 - mae: 0.0075 - val_loss: 237.7047 - val_mae: 12.6534\n",
            "Epoch 603/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 7.3904e-05 - mae: 0.0070 - val_loss: 237.9590 - val_mae: 12.6575\n",
            "Epoch 604/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.0895e-04 - mae: 0.0081 - val_loss: 238.0044 - val_mae: 12.6580\n",
            "Epoch 605/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 9.1572e-05 - mae: 0.0078 - val_loss: 237.8471 - val_mae: 12.6565\n",
            "Epoch 606/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.3922e-04 - mae: 0.0096 - val_loss: 237.6480 - val_mae: 12.6523\n",
            "Epoch 607/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6192e-04 - mae: 0.0102 - val_loss: 238.0386 - val_mae: 12.6580\n",
            "Epoch 608/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.7716e-04 - mae: 0.0100 - val_loss: 237.9855 - val_mae: 12.6596\n",
            "Epoch 609/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.7050e-04 - mae: 0.0100 - val_loss: 238.0318 - val_mae: 12.6600\n",
            "Epoch 610/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.2987e-04 - mae: 0.0082 - val_loss: 237.9026 - val_mae: 12.6543\n",
            "Epoch 611/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.7614e-04 - mae: 0.0123 - val_loss: 238.0993 - val_mae: 12.6612\n",
            "Epoch 612/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 4.0653e-04 - mae: 0.0152 - val_loss: 237.3426 - val_mae: 12.6479\n",
            "Epoch 613/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 4.6543e-04 - mae: 0.0169 - val_loss: 237.6966 - val_mae: 12.6532\n",
            "Epoch 614/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.3692e-04 - mae: 0.0192 - val_loss: 238.7424 - val_mae: 12.6764\n",
            "Epoch 615/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 9.6432e-04 - mae: 0.0240 - val_loss: 238.0459 - val_mae: 12.6641\n",
            "Epoch 616/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 7.5074e-04 - mae: 0.0206 - val_loss: 237.8983 - val_mae: 12.6589\n",
            "Epoch 617/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 9.8788e-04 - mae: 0.0250 - val_loss: 239.2557 - val_mae: 12.6869\n",
            "Epoch 618/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0011 - mae: 0.0263 - val_loss: 238.8186 - val_mae: 12.6756\n",
            "Epoch 619/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 9.6531e-04 - mae: 0.0201 - val_loss: 237.9927 - val_mae: 12.6538\n",
            "Epoch 620/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 5.4809e-04 - mae: 0.0171 - val_loss: 237.9409 - val_mae: 12.6554\n",
            "Epoch 621/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 5.9048e-04 - mae: 0.0180 - val_loss: 237.5130 - val_mae: 12.6438\n",
            "Epoch 622/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.2490e-04 - mae: 0.0137 - val_loss: 237.3487 - val_mae: 12.6412\n",
            "Epoch 623/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.2061e-04 - mae: 0.0115 - val_loss: 238.0126 - val_mae: 12.6573\n",
            "Epoch 624/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 3.7198e-04 - mae: 0.0145 - val_loss: 237.2906 - val_mae: 12.6430\n",
            "Epoch 625/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 5.7310e-04 - mae: 0.0165 - val_loss: 237.4627 - val_mae: 12.6462\n",
            "Epoch 626/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 6.4482e-04 - mae: 0.0210 - val_loss: 238.5925 - val_mae: 12.6654\n",
            "Epoch 627/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0011 - mae: 0.0266 - val_loss: 237.6011 - val_mae: 12.6447\n",
            "Epoch 628/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0017 - mae: 0.0307 - val_loss: 237.3863 - val_mae: 12.6471\n",
            "Epoch 629/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0038 - mae: 0.0491 - val_loss: 239.2497 - val_mae: 12.6838\n",
            "Epoch 630/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0046 - mae: 0.0501 - val_loss: 239.6823 - val_mae: 12.6894\n",
            "Epoch 631/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0034 - mae: 0.0420 - val_loss: 240.4406 - val_mae: 12.7059\n",
            "Epoch 632/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0027 - mae: 0.0422 - val_loss: 237.5745 - val_mae: 12.6517\n",
            "Epoch 633/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0025 - mae: 0.0388 - val_loss: 236.7737 - val_mae: 12.6311\n",
            "Epoch 634/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0034 - mae: 0.0445 - val_loss: 236.4879 - val_mae: 12.6217\n",
            "Epoch 635/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0028 - mae: 0.0398 - val_loss: 237.8654 - val_mae: 12.6532\n",
            "Epoch 636/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0051 - mae: 0.0573 - val_loss: 238.6163 - val_mae: 12.6721\n",
            "Epoch 637/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0041 - mae: 0.0502 - val_loss: 235.7066 - val_mae: 12.6146\n",
            "Epoch 638/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0144 - mae: 0.0968 - val_loss: 235.8915 - val_mae: 12.6197\n",
            "Epoch 639/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0167 - mae: 0.1057 - val_loss: 240.7821 - val_mae: 12.6873\n",
            "Epoch 640/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0411 - mae: 0.1536 - val_loss: 230.5217 - val_mae: 12.5052\n",
            "Epoch 641/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0237 - mae: 0.1116 - val_loss: 227.5181 - val_mae: 12.4682\n",
            "Epoch 642/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1221 - mae: 0.2802 - val_loss: 232.8023 - val_mae: 12.5721\n",
            "Epoch 643/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0561 - mae: 0.1944 - val_loss: 239.5956 - val_mae: 12.6781\n",
            "Epoch 644/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0816 - mae: 0.2070 - val_loss: 230.4190 - val_mae: 12.4759\n",
            "Epoch 645/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0381 - mae: 0.1166 - val_loss: 235.2473 - val_mae: 12.5724\n",
            "Epoch 646/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1095 - mae: 0.2627 - val_loss: 242.2509 - val_mae: 12.7330\n",
            "Epoch 647/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2545 - mae: 0.3186 - val_loss: 185.8812 - val_mae: 11.3807\n",
            "Epoch 648/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5992 - mae: 0.6068 - val_loss: 163.5952 - val_mae: 10.6370\n",
            "Epoch 649/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2752 - mae: 0.3863 - val_loss: 179.1249 - val_mae: 10.9653\n",
            "Epoch 650/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1896 - mae: 0.3497 - val_loss: 179.8082 - val_mae: 10.9521\n",
            "Epoch 651/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1226 - mae: 0.2831 - val_loss: 185.6577 - val_mae: 10.9964\n",
            "Epoch 652/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1178 - mae: 0.2572 - val_loss: 188.8775 - val_mae: 11.0241\n",
            "Epoch 653/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0755 - mae: 0.1992 - val_loss: 203.4202 - val_mae: 11.3588\n",
            "Epoch 654/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1484 - mae: 0.2856 - val_loss: 215.1820 - val_mae: 11.5999\n",
            "Epoch 655/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0731 - mae: 0.2113 - val_loss: 216.0146 - val_mae: 11.6134\n",
            "Epoch 656/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0779 - mae: 0.2059 - val_loss: 216.5807 - val_mae: 11.6339\n",
            "Epoch 657/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0766 - mae: 0.2184 - val_loss: 220.2974 - val_mae: 11.6938\n",
            "Epoch 658/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1382 - mae: 0.2767 - val_loss: 222.9071 - val_mae: 11.7802\n",
            "Epoch 659/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1173 - mae: 0.2640 - val_loss: 216.5991 - val_mae: 11.6518\n",
            "Epoch 660/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2194 - mae: 0.3179 - val_loss: 224.2680 - val_mae: 11.8080\n",
            "Epoch 661/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1381 - mae: 0.2930 - val_loss: 222.0735 - val_mae: 11.8082\n",
            "Epoch 662/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.2475 - mae: 0.3849 - val_loss: 214.8329 - val_mae: 11.5655\n",
            "Epoch 663/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.1363 - mae: 0.2879 - val_loss: 223.4479 - val_mae: 11.6475\n",
            "Epoch 664/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1712 - mae: 0.3339 - val_loss: 215.3537 - val_mae: 11.5183\n",
            "Epoch 665/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.3059 - mae: 0.4055 - val_loss: 215.0968 - val_mae: 11.5438\n",
            "Epoch 666/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.1626 - mae: 0.2938 - val_loss: 216.0218 - val_mae: 11.6092\n",
            "Epoch 667/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.6541 - mae: 0.5993 - val_loss: 248.1938 - val_mae: 12.3660\n",
            "Epoch 668/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 1.0302 - mae: 0.7242 - val_loss: 229.8896 - val_mae: 11.9936\n",
            "Epoch 669/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 1.3226 - mae: 0.8788 - val_loss: 197.1827 - val_mae: 11.3020\n",
            "Epoch 670/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 1.6125 - mae: 0.9390 - val_loss: 248.1501 - val_mae: 12.3587\n",
            "Epoch 671/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.4711 - mae: 0.9243 - val_loss: 281.5544 - val_mae: 13.1069\n",
            "Epoch 672/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 1.8202 - mae: 1.0700 - val_loss: 222.7853 - val_mae: 11.9122\n",
            "Epoch 673/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 1.2123 - mae: 0.8138 - val_loss: 218.6491 - val_mae: 11.7800\n",
            "Epoch 674/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.9917 - mae: 0.7731 - val_loss: 244.2979 - val_mae: 12.1449\n",
            "Epoch 675/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.8326 - mae: 0.6927 - val_loss: 254.2214 - val_mae: 12.4392\n",
            "Epoch 676/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6148 - mae: 0.5996 - val_loss: 225.8746 - val_mae: 11.7872\n",
            "Epoch 677/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.6902 - mae: 0.6210 - val_loss: 186.6881 - val_mae: 10.8826\n",
            "Epoch 678/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.4942 - mae: 0.5745 - val_loss: 203.2623 - val_mae: 11.3699\n",
            "Epoch 679/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.8635 - mae: 0.6706 - val_loss: 169.8969 - val_mae: 10.5121\n",
            "Epoch 680/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6351 - mae: 0.6115 - val_loss: 172.1208 - val_mae: 10.6706\n",
            "Epoch 681/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5576 - mae: 0.5831 - val_loss: 226.7848 - val_mae: 11.8875\n",
            "Epoch 682/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.6902 - mae: 0.6753 - val_loss: 203.2436 - val_mae: 11.3368\n",
            "Epoch 683/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.9981 - mae: 0.7896 - val_loss: 178.4144 - val_mae: 10.8626\n",
            "Epoch 684/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 1.5191 - mae: 1.0140 - val_loss: 226.5582 - val_mae: 11.9760\n",
            "Epoch 685/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.8337 - mae: 0.7039 - val_loss: 280.4163 - val_mae: 13.0209\n",
            "Epoch 686/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.6752 - mae: 0.6413 - val_loss: 232.7144 - val_mae: 12.2418\n",
            "Epoch 687/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 2.0907 - mae: 1.1590 - val_loss: 248.0089 - val_mae: 12.3941\n",
            "Epoch 688/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.3767 - mae: 0.8558 - val_loss: 302.1256 - val_mae: 13.4067\n",
            "Epoch 689/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.0248 - mae: 0.8626 - val_loss: 233.2464 - val_mae: 12.1680\n",
            "Epoch 690/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 2.1834 - mae: 1.1909 - val_loss: 226.9858 - val_mae: 12.0274\n",
            "Epoch 691/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 1.5966 - mae: 0.9887 - val_loss: 244.4598 - val_mae: 12.4631\n",
            "Epoch 692/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 2.3890 - mae: 1.2356 - val_loss: 182.4814 - val_mae: 11.0820\n",
            "Epoch 693/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.1157 - mae: 0.8310 - val_loss: 180.6899 - val_mae: 11.0794\n",
            "Epoch 694/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.7290 - mae: 0.6591 - val_loss: 197.6386 - val_mae: 11.4382\n",
            "Epoch 695/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5609 - mae: 0.5754 - val_loss: 174.0717 - val_mae: 10.8036\n",
            "Epoch 696/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5603 - mae: 0.5821 - val_loss: 193.6069 - val_mae: 11.2568\n",
            "Epoch 697/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3167 - mae: 0.4690 - val_loss: 227.1344 - val_mae: 12.0937\n",
            "Epoch 698/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.6569 - mae: 0.6222 - val_loss: 190.6845 - val_mae: 11.3207\n",
            "Epoch 699/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.4396 - mae: 0.5000 - val_loss: 214.3324 - val_mae: 11.6838\n",
            "Epoch 700/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5007 - mae: 0.5352 - val_loss: 214.8382 - val_mae: 11.7820\n",
            "Epoch 701/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.7052 - mae: 0.6182 - val_loss: 169.3086 - val_mae: 10.7222\n",
            "Epoch 702/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.9730 - mae: 0.8409 - val_loss: 182.3618 - val_mae: 11.1507\n",
            "Epoch 703/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 1.2595 - mae: 0.9043 - val_loss: 165.0667 - val_mae: 10.7872\n",
            "Epoch 704/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.7777 - mae: 0.6822 - val_loss: 153.1441 - val_mae: 10.4696\n",
            "Epoch 705/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5905 - mae: 0.5660 - val_loss: 162.2376 - val_mae: 10.5248\n",
            "Epoch 706/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.3440 - mae: 0.4822 - val_loss: 159.7872 - val_mae: 10.4867\n",
            "Epoch 707/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.1731 - mae: 0.3636 - val_loss: 176.8418 - val_mae: 10.9942\n",
            "Epoch 708/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.1903 - mae: 0.3317 - val_loss: 183.7595 - val_mae: 11.1537\n",
            "Epoch 709/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0862 - mae: 0.2190 - val_loss: 181.4538 - val_mae: 11.0882\n",
            "Epoch 710/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0760 - mae: 0.2314 - val_loss: 197.4899 - val_mae: 11.4797\n",
            "Epoch 711/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.1313 - mae: 0.2922 - val_loss: 198.1155 - val_mae: 11.4678\n",
            "Epoch 712/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.1709 - mae: 0.3298 - val_loss: 180.1307 - val_mae: 11.0247\n",
            "Epoch 713/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.1444 - mae: 0.2947 - val_loss: 203.0546 - val_mae: 11.5391\n",
            "Epoch 714/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1503 - mae: 0.3181 - val_loss: 190.1766 - val_mae: 11.2432\n",
            "Epoch 715/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1269 - mae: 0.2719 - val_loss: 190.7166 - val_mae: 11.2643\n",
            "Epoch 716/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0835 - mae: 0.2325 - val_loss: 197.3004 - val_mae: 11.3879\n",
            "Epoch 717/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.1179 - mae: 0.2710 - val_loss: 184.0720 - val_mae: 11.1427\n",
            "Epoch 718/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.1047 - mae: 0.2613 - val_loss: 205.1502 - val_mae: 11.6065\n",
            "Epoch 719/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1553 - mae: 0.2948 - val_loss: 201.9062 - val_mae: 11.5389\n",
            "Epoch 720/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0706 - mae: 0.1870 - val_loss: 186.5497 - val_mae: 11.1963\n",
            "Epoch 721/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1010 - mae: 0.2304 - val_loss: 198.8397 - val_mae: 11.4793\n",
            "Epoch 722/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0439 - mae: 0.1629 - val_loss: 204.5804 - val_mae: 11.6341\n",
            "Epoch 723/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0670 - mae: 0.2001 - val_loss: 201.0842 - val_mae: 11.5980\n",
            "Epoch 724/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1008 - mae: 0.2534 - val_loss: 209.3710 - val_mae: 11.7127\n",
            "Epoch 725/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.2009 - mae: 0.3703 - val_loss: 191.8332 - val_mae: 11.3474\n",
            "Epoch 726/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.1171 - mae: 0.2725 - val_loss: 207.3400 - val_mae: 11.7236\n",
            "Epoch 727/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.2450 - mae: 0.3472 - val_loss: 203.9166 - val_mae: 11.5862\n",
            "Epoch 728/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2644 - mae: 0.3805 - val_loss: 206.4564 - val_mae: 11.5874\n",
            "Epoch 729/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.1756 - mae: 0.3056 - val_loss: 200.8810 - val_mae: 11.5431\n",
            "Epoch 730/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.1630 - mae: 0.3203 - val_loss: 207.0931 - val_mae: 11.7060\n",
            "Epoch 731/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0907 - mae: 0.2085 - val_loss: 208.6907 - val_mae: 11.7164\n",
            "Epoch 732/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0692 - mae: 0.1835 - val_loss: 198.7295 - val_mae: 11.4969\n",
            "Epoch 733/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0722 - mae: 0.2127 - val_loss: 201.5842 - val_mae: 11.5620\n",
            "Epoch 734/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0260 - mae: 0.1263 - val_loss: 203.9826 - val_mae: 11.5911\n",
            "Epoch 735/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0258 - mae: 0.1248 - val_loss: 205.4980 - val_mae: 11.6407\n",
            "Epoch 736/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0162 - mae: 0.1002 - val_loss: 208.8988 - val_mae: 11.7295\n",
            "Epoch 737/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0324 - mae: 0.1423 - val_loss: 202.6953 - val_mae: 11.6048\n",
            "Epoch 738/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0235 - mae: 0.1184 - val_loss: 203.0866 - val_mae: 11.6186\n",
            "Epoch 739/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0148 - mae: 0.0877 - val_loss: 205.5611 - val_mae: 11.6786\n",
            "Epoch 740/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0161 - mae: 0.1031 - val_loss: 204.7618 - val_mae: 11.6414\n",
            "Epoch 741/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0071 - mae: 0.0674 - val_loss: 209.4193 - val_mae: 11.7101\n",
            "Epoch 742/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0109 - mae: 0.0872 - val_loss: 208.3733 - val_mae: 11.6963\n",
            "Epoch 743/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0114 - mae: 0.0837 - val_loss: 208.1798 - val_mae: 11.6862\n",
            "Epoch 744/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0131 - mae: 0.0846 - val_loss: 206.2673 - val_mae: 11.6392\n",
            "Epoch 745/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0121 - mae: 0.0835 - val_loss: 209.0243 - val_mae: 11.7195\n",
            "Epoch 746/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0105 - mae: 0.0775 - val_loss: 208.8471 - val_mae: 11.7216\n",
            "Epoch 747/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0052 - mae: 0.0536 - val_loss: 207.1329 - val_mae: 11.6700\n",
            "Epoch 748/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0062 - mae: 0.0593 - val_loss: 207.9171 - val_mae: 11.6895\n",
            "Epoch 749/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0053 - mae: 0.0528 - val_loss: 209.2229 - val_mae: 11.7233\n",
            "Epoch 750/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0064 - mae: 0.0637 - val_loss: 204.6082 - val_mae: 11.6235\n",
            "Epoch 751/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0062 - mae: 0.0631 - val_loss: 207.3485 - val_mae: 11.6773\n",
            "Epoch 752/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0087 - mae: 0.0762 - val_loss: 208.0635 - val_mae: 11.7070\n",
            "Epoch 753/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0098 - mae: 0.0721 - val_loss: 207.2998 - val_mae: 11.6960\n",
            "Epoch 754/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0151 - mae: 0.0987 - val_loss: 210.1533 - val_mae: 11.7384\n",
            "Epoch 755/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0199 - mae: 0.1135 - val_loss: 206.1135 - val_mae: 11.6727\n",
            "Epoch 756/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0178 - mae: 0.0984 - val_loss: 208.1602 - val_mae: 11.7006\n",
            "Epoch 757/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0154 - mae: 0.0947 - val_loss: 212.0665 - val_mae: 11.7790\n",
            "Epoch 758/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0249 - mae: 0.1293 - val_loss: 203.2279 - val_mae: 11.6151\n",
            "Epoch 759/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0327 - mae: 0.1472 - val_loss: 206.9506 - val_mae: 11.6924\n",
            "Epoch 760/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0313 - mae: 0.1241 - val_loss: 201.5296 - val_mae: 11.5648\n",
            "Epoch 761/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0220 - mae: 0.1130 - val_loss: 201.5371 - val_mae: 11.5694\n",
            "Epoch 762/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0159 - mae: 0.0881 - val_loss: 210.7245 - val_mae: 11.7809\n",
            "Epoch 763/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0160 - mae: 0.1037 - val_loss: 209.1335 - val_mae: 11.7326\n",
            "Epoch 764/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0120 - mae: 0.0850 - val_loss: 207.3482 - val_mae: 11.6892\n",
            "Epoch 765/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0044 - mae: 0.0481 - val_loss: 207.8250 - val_mae: 11.7146\n",
            "Epoch 766/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0061 - mae: 0.0588 - val_loss: 208.5193 - val_mae: 11.7325\n",
            "Epoch 767/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0059 - mae: 0.0578 - val_loss: 207.2477 - val_mae: 11.7050\n",
            "Epoch 768/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0067 - mae: 0.0623 - val_loss: 204.0957 - val_mae: 11.6338\n",
            "Epoch 769/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0104 - mae: 0.0850 - val_loss: 207.6314 - val_mae: 11.7075\n",
            "Epoch 770/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0100 - mae: 0.0834 - val_loss: 204.8917 - val_mae: 11.6461\n",
            "Epoch 771/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0097 - mae: 0.0782 - val_loss: 204.9873 - val_mae: 11.6433\n",
            "Epoch 772/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0077 - mae: 0.0694 - val_loss: 208.9187 - val_mae: 11.7505\n",
            "Epoch 773/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0123 - mae: 0.0800 - val_loss: 206.3877 - val_mae: 11.6955\n",
            "Epoch 774/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0281 - mae: 0.1264 - val_loss: 205.0928 - val_mae: 11.6713\n",
            "Epoch 775/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0248 - mae: 0.1254 - val_loss: 207.9724 - val_mae: 11.7460\n",
            "Epoch 776/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0170 - mae: 0.0936 - val_loss: 201.0528 - val_mae: 11.5686\n",
            "Epoch 777/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0151 - mae: 0.1004 - val_loss: 200.8675 - val_mae: 11.5545\n",
            "Epoch 778/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0165 - mae: 0.0966 - val_loss: 208.1057 - val_mae: 11.7283\n",
            "Epoch 779/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0148 - mae: 0.1019 - val_loss: 208.8204 - val_mae: 11.7547\n",
            "Epoch 780/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0140 - mae: 0.0923 - val_loss: 207.5037 - val_mae: 11.7225\n",
            "Epoch 781/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0141 - mae: 0.0910 - val_loss: 211.3782 - val_mae: 11.8030\n",
            "Epoch 782/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0125 - mae: 0.0856 - val_loss: 208.8324 - val_mae: 11.7503\n",
            "Epoch 783/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0335 - mae: 0.1427 - val_loss: 205.2554 - val_mae: 11.6826\n",
            "Epoch 784/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0538 - mae: 0.1870 - val_loss: 215.2565 - val_mae: 11.8891\n",
            "Epoch 785/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0269 - mae: 0.1265 - val_loss: 205.5571 - val_mae: 11.6976\n",
            "Epoch 786/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0318 - mae: 0.1310 - val_loss: 202.0918 - val_mae: 11.6119\n",
            "Epoch 787/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0119 - mae: 0.0821 - val_loss: 210.6064 - val_mae: 11.8045\n",
            "Epoch 788/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0229 - mae: 0.1138 - val_loss: 212.4503 - val_mae: 11.8582\n",
            "Epoch 789/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0189 - mae: 0.1100 - val_loss: 207.2050 - val_mae: 11.7323\n",
            "Epoch 790/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0273 - mae: 0.1309 - val_loss: 211.3344 - val_mae: 11.8087\n",
            "Epoch 791/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0633 - mae: 0.2062 - val_loss: 207.5800 - val_mae: 11.7486\n",
            "Epoch 792/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0479 - mae: 0.1484 - val_loss: 207.3864 - val_mae: 11.7462\n",
            "Epoch 793/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0374 - mae: 0.1308 - val_loss: 210.7593 - val_mae: 11.7737\n",
            "Epoch 794/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0256 - mae: 0.1238 - val_loss: 208.2563 - val_mae: 11.7156\n",
            "Epoch 795/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0158 - mae: 0.0915 - val_loss: 212.4370 - val_mae: 11.8181\n",
            "Epoch 796/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0190 - mae: 0.0965 - val_loss: 210.5557 - val_mae: 11.7908\n",
            "Epoch 797/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0094 - mae: 0.0754 - val_loss: 206.3961 - val_mae: 11.7068\n",
            "Epoch 798/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0091 - mae: 0.0716 - val_loss: 207.6564 - val_mae: 11.7412\n",
            "Epoch 799/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0069 - mae: 0.0632 - val_loss: 208.7714 - val_mae: 11.7908\n",
            "Epoch 800/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0094 - mae: 0.0684 - val_loss: 209.3715 - val_mae: 11.7967\n",
            "Epoch 801/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0087 - mae: 0.0619 - val_loss: 204.9855 - val_mae: 11.6857\n",
            "Epoch 802/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0059 - mae: 0.0587 - val_loss: 208.7047 - val_mae: 11.7492\n",
            "Epoch 803/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0110 - mae: 0.0847 - val_loss: 203.6311 - val_mae: 11.6431\n",
            "Epoch 804/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0265 - mae: 0.1169 - val_loss: 207.3306 - val_mae: 11.7347\n",
            "Epoch 805/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0168 - mae: 0.1023 - val_loss: 212.1746 - val_mae: 11.8418\n",
            "Epoch 806/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0075 - mae: 0.0711 - val_loss: 205.2178 - val_mae: 11.6958\n",
            "Epoch 807/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0191 - mae: 0.0941 - val_loss: 206.1292 - val_mae: 11.7310\n",
            "Epoch 808/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0106 - mae: 0.0759 - val_loss: 213.4304 - val_mae: 11.8955\n",
            "Epoch 809/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0140 - mae: 0.0897 - val_loss: 208.7683 - val_mae: 11.7753\n",
            "Epoch 810/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0127 - mae: 0.0868 - val_loss: 204.7702 - val_mae: 11.6846\n",
            "Epoch 811/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0119 - mae: 0.0814 - val_loss: 209.9242 - val_mae: 11.7868\n",
            "Epoch 812/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0266 - mae: 0.1170 - val_loss: 208.5442 - val_mae: 11.7525\n",
            "Epoch 813/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0125 - mae: 0.0812 - val_loss: 204.1086 - val_mae: 11.6592\n",
            "Epoch 814/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0290 - mae: 0.1349 - val_loss: 200.3669 - val_mae: 11.5581\n",
            "Epoch 815/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0752 - mae: 0.2314 - val_loss: 214.3753 - val_mae: 11.8648\n",
            "Epoch 816/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0694 - mae: 0.1907 - val_loss: 205.9553 - val_mae: 11.6805\n",
            "Epoch 817/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0288 - mae: 0.1376 - val_loss: 209.4267 - val_mae: 11.7602\n",
            "Epoch 818/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0143 - mae: 0.0920 - val_loss: 216.4892 - val_mae: 11.9162\n",
            "Epoch 819/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0111 - mae: 0.0773 - val_loss: 210.5267 - val_mae: 11.8040\n",
            "Epoch 820/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0188 - mae: 0.1101 - val_loss: 212.0516 - val_mae: 11.8378\n",
            "Epoch 821/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0216 - mae: 0.1103 - val_loss: 212.3887 - val_mae: 11.8331\n",
            "Epoch 822/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0259 - mae: 0.1174 - val_loss: 208.9561 - val_mae: 11.7672\n",
            "Epoch 823/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0549 - mae: 0.1848 - val_loss: 215.5304 - val_mae: 11.8971\n",
            "Epoch 824/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0448 - mae: 0.1546 - val_loss: 206.9142 - val_mae: 11.6762\n",
            "Epoch 825/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0424 - mae: 0.1741 - val_loss: 201.4056 - val_mae: 11.5630\n",
            "Epoch 826/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0532 - mae: 0.1748 - val_loss: 219.0099 - val_mae: 11.9821\n",
            "Epoch 827/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0693 - mae: 0.1992 - val_loss: 219.9179 - val_mae: 12.0167\n",
            "Epoch 828/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0734 - mae: 0.2051 - val_loss: 201.5607 - val_mae: 11.6113\n",
            "Epoch 829/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1142 - mae: 0.2334 - val_loss: 200.2135 - val_mae: 11.5871\n",
            "Epoch 830/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0838 - mae: 0.2155 - val_loss: 208.2518 - val_mae: 11.7560\n",
            "Epoch 831/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1221 - mae: 0.2644 - val_loss: 219.6078 - val_mae: 11.9394\n",
            "Epoch 832/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.2861 - mae: 0.4056 - val_loss: 204.0478 - val_mae: 11.6265\n",
            "Epoch 833/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2402 - mae: 0.3863 - val_loss: 204.5921 - val_mae: 11.5756\n",
            "Epoch 834/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2238 - mae: 0.3679 - val_loss: 207.4410 - val_mae: 11.6383\n",
            "Epoch 835/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1205 - mae: 0.2642 - val_loss: 191.6152 - val_mae: 11.2977\n",
            "Epoch 836/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1039 - mae: 0.2508 - val_loss: 200.7846 - val_mae: 11.4633\n",
            "Epoch 837/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1404 - mae: 0.2675 - val_loss: 208.2949 - val_mae: 11.6530\n",
            "Epoch 838/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2516 - mae: 0.4095 - val_loss: 184.6639 - val_mae: 11.1420\n",
            "Epoch 839/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4107 - mae: 0.4793 - val_loss: 200.6772 - val_mae: 11.4512\n",
            "Epoch 840/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5389 - mae: 0.5640 - val_loss: 243.6402 - val_mae: 12.4866\n",
            "Epoch 841/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2234 - mae: 0.8638 - val_loss: 213.6564 - val_mae: 11.9477\n",
            "Epoch 842/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.9207 - mae: 1.3200 - val_loss: 217.0812 - val_mae: 11.8382\n",
            "Epoch 843/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.7635 - mae: 1.2206 - val_loss: 247.4435 - val_mae: 12.3910\n",
            "Epoch 844/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.2480 - mae: 1.1061 - val_loss: 177.4513 - val_mae: 10.8201\n",
            "Epoch 845/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.8987 - mae: 1.0683 - val_loss: 196.8302 - val_mae: 11.3023\n",
            "Epoch 846/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.2894 - mae: 0.8172 - val_loss: 168.7623 - val_mae: 10.4983\n",
            "Epoch 847/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1657 - mae: 0.7844 - val_loss: 157.4936 - val_mae: 10.1572\n",
            "Epoch 848/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.5267 - mae: 0.9528 - val_loss: 193.4727 - val_mae: 11.2675\n",
            "Epoch 849/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.0186 - mae: 0.7718 - val_loss: 181.0425 - val_mae: 10.9586\n",
            "Epoch 850/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.8664 - mae: 0.7134 - val_loss: 182.9329 - val_mae: 11.1118\n",
            "Epoch 851/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.7043 - mae: 0.5982 - val_loss: 222.2895 - val_mae: 11.9967\n",
            "Epoch 852/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.8121 - mae: 0.6745 - val_loss: 207.8385 - val_mae: 11.5615\n",
            "Epoch 853/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5688 - mae: 0.6091 - val_loss: 210.3979 - val_mae: 11.6287\n",
            "Epoch 854/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3643 - mae: 0.4724 - val_loss: 212.5895 - val_mae: 11.6602\n",
            "Epoch 855/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3938 - mae: 0.4919 - val_loss: 185.7635 - val_mae: 10.9759\n",
            "Epoch 856/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.7263 - mae: 0.6275 - val_loss: 210.4805 - val_mae: 11.6311\n",
            "Epoch 857/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.8476 - mae: 0.7241 - val_loss: 236.6417 - val_mae: 12.2466\n",
            "Epoch 858/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8518 - mae: 0.6679 - val_loss: 198.2834 - val_mae: 11.4084\n",
            "Epoch 859/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6192 - mae: 0.6635 - val_loss: 233.3218 - val_mae: 12.2016\n",
            "Epoch 860/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.0260 - mae: 0.7406 - val_loss: 202.4593 - val_mae: 11.6279\n",
            "Epoch 861/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.9071 - mae: 0.7681 - val_loss: 203.7997 - val_mae: 11.6798\n",
            "Epoch 862/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8479 - mae: 0.6828 - val_loss: 223.5727 - val_mae: 12.1259\n",
            "Epoch 863/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.9788 - mae: 0.7795 - val_loss: 194.6418 - val_mae: 11.4704\n",
            "Epoch 864/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6733 - mae: 0.6634 - val_loss: 251.0394 - val_mae: 12.6295\n",
            "Epoch 865/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.9195 - mae: 0.6596 - val_loss: 205.2627 - val_mae: 11.5380\n",
            "Epoch 866/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5457 - mae: 0.6118 - val_loss: 215.0148 - val_mae: 11.8041\n",
            "Epoch 867/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7111 - mae: 0.6760 - val_loss: 220.1423 - val_mae: 11.8983\n",
            "Epoch 868/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.7117 - mae: 0.6260 - val_loss: 209.9837 - val_mae: 11.5815\n",
            "Epoch 869/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.8545 - mae: 0.6911 - val_loss: 237.8831 - val_mae: 12.2303\n",
            "Epoch 870/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.9103 - mae: 0.7316 - val_loss: 208.1292 - val_mae: 11.6889\n",
            "Epoch 871/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.7255 - mae: 0.6514 - val_loss: 243.2433 - val_mae: 12.4155\n",
            "Epoch 872/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3645 - mae: 0.4535 - val_loss: 233.3530 - val_mae: 12.1390\n",
            "Epoch 873/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.4024 - mae: 0.4493 - val_loss: 238.3346 - val_mae: 12.2372\n",
            "Epoch 874/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.2214 - mae: 0.3516 - val_loss: 249.7380 - val_mae: 12.4862\n",
            "Epoch 875/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2042 - mae: 0.3514 - val_loss: 232.3355 - val_mae: 12.1372\n",
            "Epoch 876/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2188 - mae: 0.3208 - val_loss: 247.6432 - val_mae: 12.5086\n",
            "Epoch 877/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2086 - mae: 0.3520 - val_loss: 224.6328 - val_mae: 12.0620\n",
            "Epoch 878/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.1478 - mae: 0.2948 - val_loss: 236.5614 - val_mae: 12.2210\n",
            "Epoch 879/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1567 - mae: 0.3030 - val_loss: 239.1847 - val_mae: 12.2860\n",
            "Epoch 880/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2260 - mae: 0.3373 - val_loss: 224.5414 - val_mae: 11.9891\n",
            "Epoch 881/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1515 - mae: 0.3123 - val_loss: 238.0220 - val_mae: 12.2247\n",
            "Epoch 882/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1202 - mae: 0.2751 - val_loss: 225.5963 - val_mae: 12.0053\n",
            "Epoch 883/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.1997 - mae: 0.3253 - val_loss: 263.1996 - val_mae: 12.8096\n",
            "Epoch 884/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.3253 - mae: 0.4644 - val_loss: 224.2297 - val_mae: 12.0092\n",
            "Epoch 885/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.1768 - mae: 0.3168 - val_loss: 228.8502 - val_mae: 12.0776\n",
            "Epoch 886/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.1530 - mae: 0.3361 - val_loss: 235.3978 - val_mae: 12.2624\n",
            "Epoch 887/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0733 - mae: 0.2196 - val_loss: 247.2733 - val_mae: 12.4651\n",
            "Epoch 888/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0566 - mae: 0.1990 - val_loss: 239.3846 - val_mae: 12.2830\n",
            "Epoch 889/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0406 - mae: 0.1566 - val_loss: 246.7513 - val_mae: 12.3554\n",
            "Epoch 890/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0944 - mae: 0.2136 - val_loss: 233.0579 - val_mae: 12.1276\n",
            "Epoch 891/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1270 - mae: 0.2896 - val_loss: 249.0340 - val_mae: 12.4014\n",
            "Epoch 892/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0727 - mae: 0.2152 - val_loss: 233.2886 - val_mae: 12.0881\n",
            "Epoch 893/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0905 - mae: 0.2234 - val_loss: 245.9653 - val_mae: 12.3480\n",
            "Epoch 894/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0744 - mae: 0.2130 - val_loss: 232.9464 - val_mae: 12.0977\n",
            "Epoch 895/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0598 - mae: 0.1875 - val_loss: 241.1086 - val_mae: 12.2630\n",
            "Epoch 896/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0265 - mae: 0.1163 - val_loss: 244.2391 - val_mae: 12.3715\n",
            "Epoch 897/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0187 - mae: 0.1136 - val_loss: 249.7811 - val_mae: 12.4935\n",
            "Epoch 898/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0141 - mae: 0.0908 - val_loss: 240.9150 - val_mae: 12.3063\n",
            "Epoch 899/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0156 - mae: 0.0964 - val_loss: 239.3674 - val_mae: 12.2535\n",
            "Epoch 900/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0093 - mae: 0.0693 - val_loss: 239.0466 - val_mae: 12.2670\n",
            "Epoch 901/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0106 - mae: 0.0770 - val_loss: 246.3893 - val_mae: 12.3924\n",
            "Epoch 902/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0134 - mae: 0.0898 - val_loss: 236.5963 - val_mae: 12.1821\n",
            "Epoch 903/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0259 - mae: 0.1286 - val_loss: 246.8664 - val_mae: 12.3707\n",
            "Epoch 904/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0283 - mae: 0.1388 - val_loss: 244.6113 - val_mae: 12.3611\n",
            "Epoch 905/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0405 - mae: 0.1601 - val_loss: 242.0191 - val_mae: 12.3083\n",
            "Epoch 906/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0442 - mae: 0.1520 - val_loss: 236.1737 - val_mae: 12.1526\n",
            "Epoch 907/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0383 - mae: 0.1499 - val_loss: 229.9936 - val_mae: 12.0550\n",
            "Epoch 908/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0322 - mae: 0.1272 - val_loss: 244.3615 - val_mae: 12.3546\n",
            "Epoch 909/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0201 - mae: 0.1058 - val_loss: 242.5416 - val_mae: 12.3543\n",
            "Epoch 910/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0206 - mae: 0.1005 - val_loss: 242.2023 - val_mae: 12.3430\n",
            "Epoch 911/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0085 - mae: 0.0728 - val_loss: 238.3819 - val_mae: 12.2498\n",
            "Epoch 912/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0101 - mae: 0.0720 - val_loss: 243.0721 - val_mae: 12.3464\n",
            "Epoch 913/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0049 - mae: 0.0552 - val_loss: 242.1148 - val_mae: 12.3487\n",
            "Epoch 914/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0054 - mae: 0.0544 - val_loss: 243.4072 - val_mae: 12.3660\n",
            "Epoch 915/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0043 - mae: 0.0517 - val_loss: 241.8654 - val_mae: 12.3218\n",
            "Epoch 916/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0036 - mae: 0.0410 - val_loss: 241.8454 - val_mae: 12.3161\n",
            "Epoch 917/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0049 - mae: 0.0521 - val_loss: 238.4739 - val_mae: 12.2531\n",
            "Epoch 918/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0031 - mae: 0.0404 - val_loss: 240.9710 - val_mae: 12.2949\n",
            "Epoch 919/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0020 - mae: 0.0334 - val_loss: 242.7850 - val_mae: 12.3417\n",
            "Epoch 920/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0018 - mae: 0.0307 - val_loss: 241.6746 - val_mae: 12.3220\n",
            "Epoch 921/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0020 - mae: 0.0329 - val_loss: 241.9593 - val_mae: 12.3230\n",
            "Epoch 922/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0016 - mae: 0.0274 - val_loss: 241.9201 - val_mae: 12.3273\n",
            "Epoch 923/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0015 - mae: 0.0291 - val_loss: 240.9670 - val_mae: 12.3115\n",
            "Epoch 924/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0015 - mae: 0.0279 - val_loss: 241.2438 - val_mae: 12.3105\n",
            "Epoch 925/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0011 - mae: 0.0216 - val_loss: 240.3410 - val_mae: 12.2924\n",
            "Epoch 926/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 8.9642e-04 - mae: 0.0172 - val_loss: 240.6963 - val_mae: 12.2977\n",
            "Epoch 927/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 9.9234e-04 - mae: 0.0194 - val_loss: 240.9190 - val_mae: 12.3016\n",
            "Epoch 928/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 7.2821e-04 - mae: 0.0147 - val_loss: 241.1459 - val_mae: 12.3070\n",
            "Epoch 929/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 7.1100e-04 - mae: 0.0141 - val_loss: 240.7646 - val_mae: 12.2997\n",
            "Epoch 930/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 7.2897e-04 - mae: 0.0148 - val_loss: 241.0200 - val_mae: 12.3045\n",
            "Epoch 931/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 6.3445e-04 - mae: 0.0114 - val_loss: 241.2066 - val_mae: 12.3091\n",
            "Epoch 932/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 6.1493e-04 - mae: 0.0116 - val_loss: 241.0739 - val_mae: 12.3065\n",
            "Epoch 933/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 6.4444e-04 - mae: 0.0121 - val_loss: 241.2099 - val_mae: 12.3081\n",
            "Epoch 934/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 6.0648e-04 - mae: 0.0112 - val_loss: 240.8274 - val_mae: 12.3008\n",
            "Epoch 935/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 5.8719e-04 - mae: 0.0104 - val_loss: 240.8517 - val_mae: 12.3005\n",
            "Epoch 936/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 5.1282e-04 - mae: 0.0095 - val_loss: 241.4062 - val_mae: 12.3119\n",
            "Epoch 937/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 5.5134e-04 - mae: 0.0100 - val_loss: 241.2714 - val_mae: 12.3096\n",
            "Epoch 938/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 5.3735e-04 - mae: 0.0092 - val_loss: 240.9156 - val_mae: 12.3018\n",
            "Epoch 939/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 5.0064e-04 - mae: 0.0090 - val_loss: 240.7817 - val_mae: 12.2984\n",
            "Epoch 940/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 5.2406e-04 - mae: 0.0092 - val_loss: 240.9688 - val_mae: 12.3017\n",
            "Epoch 941/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 5.0088e-04 - mae: 0.0077 - val_loss: 241.0031 - val_mae: 12.3031\n",
            "Epoch 942/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 4.7504e-04 - mae: 0.0084 - val_loss: 241.2062 - val_mae: 12.3068\n",
            "Epoch 943/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 4.5989e-04 - mae: 0.0071 - val_loss: 241.2227 - val_mae: 12.3058\n",
            "Epoch 944/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 5.0278e-04 - mae: 0.0079 - val_loss: 241.1445 - val_mae: 12.3041\n",
            "Epoch 945/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 5.9404e-04 - mae: 0.0115 - val_loss: 241.4176 - val_mae: 12.3102\n",
            "Epoch 946/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 5.0355e-04 - mae: 0.0106 - val_loss: 240.8958 - val_mae: 12.2980\n",
            "Epoch 947/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 5.0421e-04 - mae: 0.0114 - val_loss: 241.0266 - val_mae: 12.2994\n",
            "Epoch 948/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 4.9717e-04 - mae: 0.0106 - val_loss: 240.9579 - val_mae: 12.2988\n",
            "Epoch 949/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 4.6066e-04 - mae: 0.0088 - val_loss: 241.4328 - val_mae: 12.3081\n",
            "Epoch 950/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 5.3059e-04 - mae: 0.0117 - val_loss: 241.0325 - val_mae: 12.3002\n",
            "Epoch 951/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 4.5401e-04 - mae: 0.0093 - val_loss: 240.7471 - val_mae: 12.2932\n",
            "Epoch 952/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 4.8454e-04 - mae: 0.0108 - val_loss: 241.0302 - val_mae: 12.2983\n",
            "Epoch 953/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 6.6573e-04 - mae: 0.0175 - val_loss: 240.6666 - val_mae: 12.2939\n",
            "Epoch 954/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 6.1589e-04 - mae: 0.0155 - val_loss: 241.2069 - val_mae: 12.3022\n",
            "Epoch 955/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 7.5594e-04 - mae: 0.0176 - val_loss: 240.6178 - val_mae: 12.2917\n",
            "Epoch 956/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 7.3991e-04 - mae: 0.0173 - val_loss: 241.2385 - val_mae: 12.3034\n",
            "Epoch 957/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 6.0148e-04 - mae: 0.0155 - val_loss: 240.7000 - val_mae: 12.2891\n",
            "Epoch 958/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 7.1691e-04 - mae: 0.0175 - val_loss: 240.4522 - val_mae: 12.2838\n",
            "Epoch 959/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 5.5250e-04 - mae: 0.0134 - val_loss: 241.6618 - val_mae: 12.3113\n",
            "Epoch 960/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 6.6476e-04 - mae: 0.0165 - val_loss: 241.2661 - val_mae: 12.2997\n",
            "Epoch 961/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 5.4941e-04 - mae: 0.0137 - val_loss: 240.6870 - val_mae: 12.2870\n",
            "Epoch 962/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 4.4816e-04 - mae: 0.0127 - val_loss: 241.4845 - val_mae: 12.3047\n",
            "Epoch 963/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 4.5371e-04 - mae: 0.0119 - val_loss: 240.7421 - val_mae: 12.2891\n",
            "Epoch 964/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 3.9912e-04 - mae: 0.0101 - val_loss: 240.6153 - val_mae: 12.2843\n",
            "Epoch 965/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 4.3063e-04 - mae: 0.0118 - val_loss: 241.0328 - val_mae: 12.2952\n",
            "Epoch 966/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 5.5020e-04 - mae: 0.0149 - val_loss: 240.9612 - val_mae: 12.2945\n",
            "Epoch 967/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 3.9998e-04 - mae: 0.0113 - val_loss: 240.7583 - val_mae: 12.2882\n",
            "Epoch 968/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 5.1529e-04 - mae: 0.0147 - val_loss: 240.4182 - val_mae: 12.2830\n",
            "Epoch 969/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 4.5534e-04 - mae: 0.0139 - val_loss: 241.2095 - val_mae: 12.2976\n",
            "Epoch 970/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 4.3658e-04 - mae: 0.0123 - val_loss: 241.3384 - val_mae: 12.3005\n",
            "Epoch 971/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 3.5095e-04 - mae: 0.0096 - val_loss: 241.0681 - val_mae: 12.2957\n",
            "Epoch 972/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 3.5659e-04 - mae: 0.0103 - val_loss: 241.1396 - val_mae: 12.2957\n",
            "Epoch 973/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 3.1693e-04 - mae: 0.0084 - val_loss: 240.8348 - val_mae: 12.2883\n",
            "Epoch 974/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 3.5271e-04 - mae: 0.0106 - val_loss: 240.8918 - val_mae: 12.2874\n",
            "Epoch 975/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 4.1733e-04 - mae: 0.0120 - val_loss: 240.8365 - val_mae: 12.2871\n",
            "Epoch 976/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 3.3504e-04 - mae: 0.0088 - val_loss: 240.7713 - val_mae: 12.2836\n",
            "Epoch 977/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 3.5761e-04 - mae: 0.0103 - val_loss: 240.9839 - val_mae: 12.2885\n",
            "Epoch 978/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 3.2746e-04 - mae: 0.0084 - val_loss: 240.8933 - val_mae: 12.2847\n",
            "Epoch 979/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 3.3012e-04 - mae: 0.0094 - val_loss: 241.1905 - val_mae: 12.2910\n",
            "Epoch 980/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.8724e-04 - mae: 0.0082 - val_loss: 241.2057 - val_mae: 12.2915\n",
            "Epoch 981/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 2.8171e-04 - mae: 0.0079 - val_loss: 241.0949 - val_mae: 12.2895\n",
            "Epoch 982/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 3.0123e-04 - mae: 0.0081 - val_loss: 240.8785 - val_mae: 12.2855\n",
            "Epoch 983/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.5197e-04 - mae: 0.0071 - val_loss: 240.8710 - val_mae: 12.2856\n",
            "Epoch 984/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.6221e-04 - mae: 0.0078 - val_loss: 241.1647 - val_mae: 12.2904\n",
            "Epoch 985/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 3.0989e-04 - mae: 0.0093 - val_loss: 240.9595 - val_mae: 12.2864\n",
            "Epoch 986/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.9882e-04 - mae: 0.0099 - val_loss: 240.6688 - val_mae: 12.2813\n",
            "Epoch 987/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 2.5956e-04 - mae: 0.0083 - val_loss: 240.9878 - val_mae: 12.2865\n",
            "Epoch 988/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 2.9825e-04 - mae: 0.0092 - val_loss: 240.5005 - val_mae: 12.2760\n",
            "Epoch 989/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 2.5408e-04 - mae: 0.0085 - val_loss: 240.6072 - val_mae: 12.2783\n",
            "Epoch 990/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 2.7559e-04 - mae: 0.0091 - val_loss: 240.8517 - val_mae: 12.2824\n",
            "Epoch 991/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 3.3040e-04 - mae: 0.0119 - val_loss: 240.9959 - val_mae: 12.2865\n",
            "Epoch 992/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 3.6020e-04 - mae: 0.0119 - val_loss: 241.3925 - val_mae: 12.2930\n",
            "Epoch 993/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.8478e-04 - mae: 0.0110 - val_loss: 240.9917 - val_mae: 12.2836\n",
            "Epoch 994/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 5.0535e-04 - mae: 0.0137 - val_loss: 240.8057 - val_mae: 12.2787\n",
            "Epoch 995/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 3.5287e-04 - mae: 0.0114 - val_loss: 241.0734 - val_mae: 12.2871\n",
            "Epoch 996/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 5.8528e-04 - mae: 0.0181 - val_loss: 241.0545 - val_mae: 12.2835\n",
            "Epoch 997/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 4.8362e-04 - mae: 0.0149 - val_loss: 239.7604 - val_mae: 12.2565\n",
            "Epoch 998/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 6.6238e-04 - mae: 0.0178 - val_loss: 240.4636 - val_mae: 12.2725\n",
            "Epoch 999/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 4.3047e-04 - mae: 0.0126 - val_loss: 241.0538 - val_mae: 12.2855\n",
            "Epoch 1000/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 2.8086e-04 - mae: 0.0106 - val_loss: 240.4964 - val_mae: 12.2734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2sj09WfmKp-z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}